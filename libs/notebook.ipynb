{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucas.boscatti/Documents/nero/nero_chatbot/.venv/lib/python3.10/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import os\n",
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "import streamlit as st\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import AIMessage, BaseMessage, convert_to_messages\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langgraph.graph import END, StateGraph, add_messages\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = st.secrets[\"TAVILY_API_KEY\"]\n",
    "os.environ[\"COHERE_API_KEY\"] = st.secrets[\"COHERE_API_KEY\"]\n",
    "os.environ[\"PINECONE_API_KEY\"] = st.secrets[\"PINECONE_API_KEY\"]\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = st.secrets[\"LANGCHAIN_API_KEY\"]\n",
    "PINECONE_INDEX = st.secrets[\"PINECONE_INDEX\"]\n",
    "\n",
    "MAX_RETRIES = 3\n",
    "VERBOSE = False\n",
    "\n",
    "tavily_search_tool = TavilySearchResults(max_results=3)\n",
    "embeddings = CohereEmbeddings(cohere_api_key=st.secrets[\"COHERE_API_KEY\"], model=\"embed-multilingual-v3.0\")\n",
    "vectorstore = PineconeVectorStore(index_name=PINECONE_INDEX, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        ask_question: whether to ask questions\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "    question: str\n",
    "    documents: list[Document]\n",
    "    candidate_answer: str\n",
    "    retries: int\n",
    "    web_fallback: bool\n",
    "\n",
    "\n",
    "class GraphConfig(TypedDict):\n",
    "    max_retries: int\n",
    "\n",
    "\n",
    "def document_search(state: GraphState):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    if VERBOSE:\n",
    "        logger.info(\"---RETRIEVE---\")\n",
    "\n",
    "    question = convert_to_messages(state[\"messages\"])[-1].content\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question, \"web_fallback\": True}\n",
    "\n",
    "\n",
    "RAG_PROMPT = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.\n",
    "Use three sentences maximum and keep the answer concise \n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer: \n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    ")\n",
    "\n",
    "\n",
    "def generate(state: GraphState):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    if VERBOSE:\n",
    "        logger.info(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    retries = state[\"retries\"] if state.get(\"retries\") is not None else -1\n",
    "\n",
    "    rag_chain = RAG_PROMPT | llm | StrOutputParser()\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"retries\": retries + 1, \"candidate_answer\": generation}\n",
    "\n",
    "\n",
    "QUERY_REWRITER_PROMPT = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You a question re-writer that converts an input question to a better version that is optimized for vectorstore retrieval.\n",
    "Look at the input and try to reason about the underlying semantic intent / meaning. \n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "Here is the initial question: \\n\\n {question} \\n Formulate an improved question. \n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "\n",
    "def transform_query(state: GraphState):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "    if VERBOSE:\n",
    "        logger.info(\"---TRANSFORM QUERY---\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Re-write question\n",
    "    query_rewriter = QUERY_REWRITER_PROMPT | llm | StrOutputParser()\n",
    "    better_question = query_rewriter.invoke({\"question\": question})\n",
    "    return {\"question\": better_question}\n",
    "\n",
    "\n",
    "def web_search(state: GraphState):\n",
    "    if VERBOSE:\n",
    "        logger.info(\"---RUNNING WEB SEARCH---\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    search_results = tavily_search_tool.invoke(question)\n",
    "    search_content = \"\\n\".join([d[\"content\"] for d in search_results])\n",
    "    documents.append(\n",
    "        Document(page_content=search_content, metadata={\"source\": \"websearch\"})\n",
    "    )\n",
    "    return {\"documents\": documents, \"web_fallback\": False}\n",
    "\n",
    "\n",
    "def finalize_response(state: GraphState):\n",
    "    if VERBOSE:\n",
    "        logger.info(\"---FINALIZING THE RESPONSE---\")\n",
    "\n",
    "    return {\"messages\": [AIMessage(content=state[\"candidate_answer\"])]}\n",
    "\n",
    "\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "HALLUCINATION_GRADER_PROMPT = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts.\n",
    "Give a binary score 'yes' or 'no', where 'yes' means that the answer is grounded in / supported by the set of facts.\n",
    "\n",
    "IF the generation includes code examples, make sure those examples are FULLY present in the set of facts, otherwise always return score 'no'. \n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"documents\", \"generation\"],\n",
    ")\n",
    "\n",
    "\n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "ANSWER_GRADER_PROMPT = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an answer addresses / resolves a question.\n",
    "Give a binary score 'yes' or 'no', where 'yes' means that the answer resolves the question. \n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "User question: \\n\\n {question} \\n\\n LLM generation: {generation}\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\", \"generation\"],\n",
    ")\n",
    "\n",
    "\n",
    "def grade_generation_v_documents_and_question(\n",
    "    state: GraphState, config\n",
    ") -> Literal[\"generate\", \"transform_query\", \"web_search\", \"finalize_response\"]:\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"candidate_answer\"]\n",
    "    web_fallback = state[\"web_fallback\"]\n",
    "    retries = state[\"retries\"] if state.get(\"retries\") is not None else -1\n",
    "    max_retries = config.get(\"configurable\", {}).get(\"max_retries\", MAX_RETRIES)\n",
    "\n",
    "    # this means we've already gone through web fallback and can return to the user\n",
    "    if not web_fallback:\n",
    "        return \"finalize_response\"\n",
    "\n",
    "    if VERBOSE:\n",
    "        logger.info(\"---CHECK HALLUCINATIONS---\")\n",
    "\n",
    "    hallucination_grader = HALLUCINATION_GRADER_PROMPT | llm.with_structured_output(\n",
    "        GradeHallucinations\n",
    "    )\n",
    "    hallucination_grade: GradeHallucinations = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "\n",
    "    # Check hallucination\n",
    "    if hallucination_grade.binary_score == \"no\":\n",
    "        if VERBOSE:\n",
    "            logger.info(\n",
    "                \"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\"\n",
    "            )\n",
    "        return \"generate\" if retries < max_retries else \"web_search\"\n",
    "\n",
    "    if VERBOSE:\n",
    "        logger.info(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        logger.info(\"---GRADE GENERATION vs QUESTION---\")\n",
    "\n",
    "    # Check question-answering\n",
    "    answer_grader = ANSWER_GRADER_PROMPT | llm.with_structured_output(GradeAnswer)\n",
    "    answer_grade: GradeAnswer = answer_grader.invoke(\n",
    "        {\"question\": question, \"generation\": generation}\n",
    "    )\n",
    "    if answer_grade.binary_score == \"yes\":\n",
    "        if VERBOSE:\n",
    "            logger.info(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "        return \"finalize_response\"\n",
    "    else:\n",
    "        if VERBOSE:\n",
    "            logger.info(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "        return \"transform_query\" if retries < max_retries else \"web_search\"\n",
    "\n",
    "\n",
    "workflow = StateGraph(GraphState, config_schema=GraphConfig)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"document_search\", document_search)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"transform_query\", transform_query)\n",
    "workflow.add_node(\"web_search\", web_search)\n",
    "workflow.add_node(\"finalize_response\", finalize_response)\n",
    "\n",
    "# Build graph\n",
    "workflow.set_entry_point(\"document_search\")\n",
    "workflow.add_edge(\"document_search\", \"generate\")\n",
    "workflow.add_edge(\"transform_query\", \"document_search\")\n",
    "workflow.add_edge(\"web_search\", \"generate\")\n",
    "workflow.add_edge(\"finalize_response\", END)\n",
    "\n",
    "workflow.add_conditional_edges(\"generate\", grade_generation_v_documents_and_question)\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_start', 'data': {'input': {'messages': [('human', 'what is human robotic')]}}, 'name': 'LangGraph', 'tags': [], 'run_id': 'e0530f4e-58ac-40f3-8d10-ceb0c50030f2', 'metadata': {}, 'parent_ids': []}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_start', 'data': {'input': {'messages': [('human', 'what is human robotic')]}}, 'name': '__start__', 'tags': ['graph:step:0', 'langsmith:hidden'], 'run_id': 'c39d6bca-c04f-405a-a30e-469878bfb8dd', 'metadata': {'langgraph_step': 0, 'langgraph_node': '__start__', 'langgraph_triggers': ['__start__'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_end', 'data': {'output': {'messages': [('human', 'what is human robotic')]}, 'input': {'messages': [('human', 'what is human robotic')]}}, 'run_id': 'c39d6bca-c04f-405a-a30e-469878bfb8dd', 'name': '__start__', 'tags': ['graph:step:0', 'langsmith:hidden'], 'metadata': {'langgraph_step': 0, 'langgraph_node': '__start__', 'langgraph_triggers': ['__start__'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_start', 'data': {}, 'name': 'document_search', 'tags': ['graph:step:1'], 'run_id': '7cd8ec44-788e-475c-9405-d1abf7ef1ca0', 'metadata': {'langgraph_step': 1, 'langgraph_node': 'document_search', 'langgraph_triggers': ['start:document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_retriever_start', 'data': {'input': {'query': 'what is human robotic'}}, 'name': 'VectorStoreRetriever', 'tags': ['seq:step:1', 'PineconeVectorStore', 'CohereEmbeddings'], 'run_id': 'a93228a7-1962-4240-a884-eba92947a795', 'metadata': {'langgraph_step': 1, 'langgraph_node': 'document_search', 'langgraph_triggers': ['start:document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '7cd8ec44-788e-475c-9405-d1abf7ef1ca0']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_retriever_end', 'data': {'output': [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\ndedicated to understand, design, and evaluate robotic systems\\nfor use by or with humans” [1]. The interaction can occur in\\ntwo different ways: remote and proximate. They are largely\\ninfluenced by the proximity of the human and the robot.\\nWorks like [2–5] bring good examples of how remote com-\\nmunication can be exploited in several applications, such as\\n\\n\\n\\x02    Kevin Braathen de Carvalho\\n     kevin.carvalho@ufv.br\\n     Daniel Khede Dourado Villa\\n     danielkdv@gmail.com\\n\\n     M´ario Sarcinelli-Filho\\n     mario.sarcinelli@ufes.br\\n     Alexandre Santos Brand˜ao\\n     alexandre.brandao@ufv.br\\n\\n1    Graduate Program on Computer Science, Federal University\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\n2    Graduate Program on Electrical Engineering, Federal\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\nranging from face, gesture, movement and speech pattern\\nrecognition, yet much to be developed. There are various\\napplications for robotics such as control – for general mobile\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\nsecurity and surveillance robots [11], home automation [12],\\nin-car recognition and many others, all of which require\\nsome level of interaction with humans, preferably as a two-\\nway conversation [13], [14]. Although efficient, most of the\\nprevious works bases themselves on recognition of phonemes\\nor a small, fixed set of keywords, usually in controlled\\nenvironments, which limits their flexibility and replicability.\\nOur goal is developing a natural, intuitive interface, working\\nas a small conversation between an autonomous robot and\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\nlow-cost solution, unlocking new possibilities for further study\\nand development of better, more autonomous and environment-\\nadaptable robots.\\n                       I. INTRODUCTION\\n   Developing robots capable of autonomously deciding the\\nbest course of action depending on events, environment and\\nuser specifications, are one of the major goals in robotics\\nand correctly perceiving these user’s specifications is critical\\nfor making decisions and acting in the most reasonable way.\\nTherefore a Human-Robot Interface (HRI) capable of both\\nsatisfying the user and performing real time task decision\\nmaking according to environmental changes is a current\\nchallenge.\\n   There are multiple models for HRI, and existing literature\\nsuggests speech recognition is user-friendly, intuitive and\\neffective for various applications [1], [2], [3], [4]. Many\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\nAssistive Robotics.\\n    This paper main contribution is a human–robot interaction frame-\\nwork, having as motivation the development of a Social Assistive\\nRobotics application. The system has easy-to-follow implementation\\nand provides a clear path to be used as a more hands-on approach.\\nIts topics facilitate the teaching tasks, for instance, the description and\\nthe response of an action classifier for a real-world agent. The Artificial\\nNeural Networks (ANN) based classifier relies on dimension reduction\\nto the system’s inputs in order to require a smaller dataset for training.\\nTo achieve it, initially, an external depth sensor provides the skeleton\\njoints features, and then eigenvalues decomposition reduces the input’s\\ndimension. The major insight of the work was the requirement of\\na tiny dataset, being flexible for several applications. In this work,')], 'input': {'query': 'what is human robotic'}}, 'run_id': 'a93228a7-1962-4240-a884-eba92947a795', 'name': 'VectorStoreRetriever', 'tags': ['seq:step:1', 'PineconeVectorStore', 'CohereEmbeddings'], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'document_search', 'langgraph_triggers': ['start:document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '7cd8ec44-788e-475c-9405-d1abf7ef1ca0']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_start', 'data': {'input': {'documents': [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\ndedicated to understand, design, and evaluate robotic systems\\nfor use by or with humans” [1]. The interaction can occur in\\ntwo different ways: remote and proximate. They are largely\\ninfluenced by the proximity of the human and the robot.\\nWorks like [2–5] bring good examples of how remote com-\\nmunication can be exploited in several applications, such as\\n\\n\\n\\x02    Kevin Braathen de Carvalho\\n     kevin.carvalho@ufv.br\\n     Daniel Khede Dourado Villa\\n     danielkdv@gmail.com\\n\\n     M´ario Sarcinelli-Filho\\n     mario.sarcinelli@ufes.br\\n     Alexandre Santos Brand˜ao\\n     alexandre.brandao@ufv.br\\n\\n1    Graduate Program on Computer Science, Federal University\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\n2    Graduate Program on Electrical Engineering, Federal\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\nranging from face, gesture, movement and speech pattern\\nrecognition, yet much to be developed. There are various\\napplications for robotics such as control – for general mobile\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\nsecurity and surveillance robots [11], home automation [12],\\nin-car recognition and many others, all of which require\\nsome level of interaction with humans, preferably as a two-\\nway conversation [13], [14]. Although efficient, most of the\\nprevious works bases themselves on recognition of phonemes\\nor a small, fixed set of keywords, usually in controlled\\nenvironments, which limits their flexibility and replicability.\\nOur goal is developing a natural, intuitive interface, working\\nas a small conversation between an autonomous robot and\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\nlow-cost solution, unlocking new possibilities for further study\\nand development of better, more autonomous and environment-\\nadaptable robots.\\n                       I. INTRODUCTION\\n   Developing robots capable of autonomously deciding the\\nbest course of action depending on events, environment and\\nuser specifications, are one of the major goals in robotics\\nand correctly perceiving these user’s specifications is critical\\nfor making decisions and acting in the most reasonable way.\\nTherefore a Human-Robot Interface (HRI) capable of both\\nsatisfying the user and performing real time task decision\\nmaking according to environmental changes is a current\\nchallenge.\\n   There are multiple models for HRI, and existing literature\\nsuggests speech recognition is user-friendly, intuitive and\\neffective for various applications [1], [2], [3], [4]. Many\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\nAssistive Robotics.\\n    This paper main contribution is a human–robot interaction frame-\\nwork, having as motivation the development of a Social Assistive\\nRobotics application. The system has easy-to-follow implementation\\nand provides a clear path to be used as a more hands-on approach.\\nIts topics facilitate the teaching tasks, for instance, the description and\\nthe response of an action classifier for a real-world agent. The Artificial\\nNeural Networks (ANN) based classifier relies on dimension reduction\\nto the system’s inputs in order to require a smaller dataset for training.\\nTo achieve it, initially, an external depth sensor provides the skeleton\\njoints features, and then eigenvalues decomposition reduces the input’s\\ndimension. The major insight of the work was the requirement of\\na tiny dataset, being flexible for several applications. In this work,')], 'question': 'what is human robotic', 'web_fallback': True}}, 'name': 'ChannelWrite<document_search,messages,question,documents,candidate_answer,retries,web_fallback>', 'tags': ['seq:step:2', 'langsmith:hidden'], 'run_id': '8f474893-d930-4b12-b297-4a3fda2cf782', 'metadata': {'langgraph_step': 1, 'langgraph_node': 'document_search', 'langgraph_triggers': ['start:document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '7cd8ec44-788e-475c-9405-d1abf7ef1ca0']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_end', 'data': {'output': {'documents': [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\ndedicated to understand, design, and evaluate robotic systems\\nfor use by or with humans” [1]. The interaction can occur in\\ntwo different ways: remote and proximate. They are largely\\ninfluenced by the proximity of the human and the robot.\\nWorks like [2–5] bring good examples of how remote com-\\nmunication can be exploited in several applications, such as\\n\\n\\n\\x02    Kevin Braathen de Carvalho\\n     kevin.carvalho@ufv.br\\n     Daniel Khede Dourado Villa\\n     danielkdv@gmail.com\\n\\n     M´ario Sarcinelli-Filho\\n     mario.sarcinelli@ufes.br\\n     Alexandre Santos Brand˜ao\\n     alexandre.brandao@ufv.br\\n\\n1    Graduate Program on Computer Science, Federal University\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\n2    Graduate Program on Electrical Engineering, Federal\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\nranging from face, gesture, movement and speech pattern\\nrecognition, yet much to be developed. There are various\\napplications for robotics such as control – for general mobile\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\nsecurity and surveillance robots [11], home automation [12],\\nin-car recognition and many others, all of which require\\nsome level of interaction with humans, preferably as a two-\\nway conversation [13], [14]. Although efficient, most of the\\nprevious works bases themselves on recognition of phonemes\\nor a small, fixed set of keywords, usually in controlled\\nenvironments, which limits their flexibility and replicability.\\nOur goal is developing a natural, intuitive interface, working\\nas a small conversation between an autonomous robot and\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\nlow-cost solution, unlocking new possibilities for further study\\nand development of better, more autonomous and environment-\\nadaptable robots.\\n                       I. INTRODUCTION\\n   Developing robots capable of autonomously deciding the\\nbest course of action depending on events, environment and\\nuser specifications, are one of the major goals in robotics\\nand correctly perceiving these user’s specifications is critical\\nfor making decisions and acting in the most reasonable way.\\nTherefore a Human-Robot Interface (HRI) capable of both\\nsatisfying the user and performing real time task decision\\nmaking according to environmental changes is a current\\nchallenge.\\n   There are multiple models for HRI, and existing literature\\nsuggests speech recognition is user-friendly, intuitive and\\neffective for various applications [1], [2], [3], [4]. Many\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\nAssistive Robotics.\\n    This paper main contribution is a human–robot interaction frame-\\nwork, having as motivation the development of a Social Assistive\\nRobotics application. The system has easy-to-follow implementation\\nand provides a clear path to be used as a more hands-on approach.\\nIts topics facilitate the teaching tasks, for instance, the description and\\nthe response of an action classifier for a real-world agent. The Artificial\\nNeural Networks (ANN) based classifier relies on dimension reduction\\nto the system’s inputs in order to require a smaller dataset for training.\\nTo achieve it, initially, an external depth sensor provides the skeleton\\njoints features, and then eigenvalues decomposition reduces the input’s\\ndimension. The major insight of the work was the requirement of\\na tiny dataset, being flexible for several applications. In this work,')], 'question': 'what is human robotic', 'web_fallback': True}, 'input': {'documents': [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\ndedicated to understand, design, and evaluate robotic systems\\nfor use by or with humans” [1]. The interaction can occur in\\ntwo different ways: remote and proximate. They are largely\\ninfluenced by the proximity of the human and the robot.\\nWorks like [2–5] bring good examples of how remote com-\\nmunication can be exploited in several applications, such as\\n\\n\\n\\x02    Kevin Braathen de Carvalho\\n     kevin.carvalho@ufv.br\\n     Daniel Khede Dourado Villa\\n     danielkdv@gmail.com\\n\\n     M´ario Sarcinelli-Filho\\n     mario.sarcinelli@ufes.br\\n     Alexandre Santos Brand˜ao\\n     alexandre.brandao@ufv.br\\n\\n1    Graduate Program on Computer Science, Federal University\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\n2    Graduate Program on Electrical Engineering, Federal\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\nranging from face, gesture, movement and speech pattern\\nrecognition, yet much to be developed. There are various\\napplications for robotics such as control – for general mobile\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\nsecurity and surveillance robots [11], home automation [12],\\nin-car recognition and many others, all of which require\\nsome level of interaction with humans, preferably as a two-\\nway conversation [13], [14]. Although efficient, most of the\\nprevious works bases themselves on recognition of phonemes\\nor a small, fixed set of keywords, usually in controlled\\nenvironments, which limits their flexibility and replicability.\\nOur goal is developing a natural, intuitive interface, working\\nas a small conversation between an autonomous robot and\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\nlow-cost solution, unlocking new possibilities for further study\\nand development of better, more autonomous and environment-\\nadaptable robots.\\n                       I. INTRODUCTION\\n   Developing robots capable of autonomously deciding the\\nbest course of action depending on events, environment and\\nuser specifications, are one of the major goals in robotics\\nand correctly perceiving these user’s specifications is critical\\nfor making decisions and acting in the most reasonable way.\\nTherefore a Human-Robot Interface (HRI) capable of both\\nsatisfying the user and performing real time task decision\\nmaking according to environmental changes is a current\\nchallenge.\\n   There are multiple models for HRI, and existing literature\\nsuggests speech recognition is user-friendly, intuitive and\\neffective for various applications [1], [2], [3], [4]. Many\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\nAssistive Robotics.\\n    This paper main contribution is a human–robot interaction frame-\\nwork, having as motivation the development of a Social Assistive\\nRobotics application. The system has easy-to-follow implementation\\nand provides a clear path to be used as a more hands-on approach.\\nIts topics facilitate the teaching tasks, for instance, the description and\\nthe response of an action classifier for a real-world agent. The Artificial\\nNeural Networks (ANN) based classifier relies on dimension reduction\\nto the system’s inputs in order to require a smaller dataset for training.\\nTo achieve it, initially, an external depth sensor provides the skeleton\\njoints features, and then eigenvalues decomposition reduces the input’s\\ndimension. The major insight of the work was the requirement of\\na tiny dataset, being flexible for several applications. In this work,')], 'question': 'what is human robotic', 'web_fallback': True}}, 'run_id': '8f474893-d930-4b12-b297-4a3fda2cf782', 'name': 'ChannelWrite<document_search,messages,question,documents,candidate_answer,retries,web_fallback>', 'tags': ['seq:step:2', 'langsmith:hidden'], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'document_search', 'langgraph_triggers': ['start:document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '7cd8ec44-788e-475c-9405-d1abf7ef1ca0']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_stream', 'run_id': '7cd8ec44-788e-475c-9405-d1abf7ef1ca0', 'name': 'document_search', 'tags': ['graph:step:1'], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'document_search', 'langgraph_triggers': ['start:document_search'], 'langgraph_task_idx': 0}, 'data': {'chunk': {'documents': [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\ndedicated to understand, design, and evaluate robotic systems\\nfor use by or with humans” [1]. The interaction can occur in\\ntwo different ways: remote and proximate. They are largely\\ninfluenced by the proximity of the human and the robot.\\nWorks like [2–5] bring good examples of how remote com-\\nmunication can be exploited in several applications, such as\\n\\n\\n\\x02    Kevin Braathen de Carvalho\\n     kevin.carvalho@ufv.br\\n     Daniel Khede Dourado Villa\\n     danielkdv@gmail.com\\n\\n     M´ario Sarcinelli-Filho\\n     mario.sarcinelli@ufes.br\\n     Alexandre Santos Brand˜ao\\n     alexandre.brandao@ufv.br\\n\\n1    Graduate Program on Computer Science, Federal University\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\n2    Graduate Program on Electrical Engineering, Federal\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\nranging from face, gesture, movement and speech pattern\\nrecognition, yet much to be developed. There are various\\napplications for robotics such as control – for general mobile\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\nsecurity and surveillance robots [11], home automation [12],\\nin-car recognition and many others, all of which require\\nsome level of interaction with humans, preferably as a two-\\nway conversation [13], [14]. Although efficient, most of the\\nprevious works bases themselves on recognition of phonemes\\nor a small, fixed set of keywords, usually in controlled\\nenvironments, which limits their flexibility and replicability.\\nOur goal is developing a natural, intuitive interface, working\\nas a small conversation between an autonomous robot and\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\nlow-cost solution, unlocking new possibilities for further study\\nand development of better, more autonomous and environment-\\nadaptable robots.\\n                       I. INTRODUCTION\\n   Developing robots capable of autonomously deciding the\\nbest course of action depending on events, environment and\\nuser specifications, are one of the major goals in robotics\\nand correctly perceiving these user’s specifications is critical\\nfor making decisions and acting in the most reasonable way.\\nTherefore a Human-Robot Interface (HRI) capable of both\\nsatisfying the user and performing real time task decision\\nmaking according to environmental changes is a current\\nchallenge.\\n   There are multiple models for HRI, and existing literature\\nsuggests speech recognition is user-friendly, intuitive and\\neffective for various applications [1], [2], [3], [4]. Many\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\nAssistive Robotics.\\n    This paper main contribution is a human–robot interaction frame-\\nwork, having as motivation the development of a Social Assistive\\nRobotics application. The system has easy-to-follow implementation\\nand provides a clear path to be used as a more hands-on approach.\\nIts topics facilitate the teaching tasks, for instance, the description and\\nthe response of an action classifier for a real-world agent. The Artificial\\nNeural Networks (ANN) based classifier relies on dimension reduction\\nto the system’s inputs in order to require a smaller dataset for training.\\nTo achieve it, initially, an external depth sensor provides the skeleton\\njoints features, and then eigenvalues decomposition reduces the input’s\\ndimension. The major insight of the work was the requirement of\\na tiny dataset, being flexible for several applications. In this work,')], 'question': 'what is human robotic', 'web_fallback': True}}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_end', 'data': {'output': {'documents': [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\ndedicated to understand, design, and evaluate robotic systems\\nfor use by or with humans” [1]. The interaction can occur in\\ntwo different ways: remote and proximate. They are largely\\ninfluenced by the proximity of the human and the robot.\\nWorks like [2–5] bring good examples of how remote com-\\nmunication can be exploited in several applications, such as\\n\\n\\n\\x02    Kevin Braathen de Carvalho\\n     kevin.carvalho@ufv.br\\n     Daniel Khede Dourado Villa\\n     danielkdv@gmail.com\\n\\n     M´ario Sarcinelli-Filho\\n     mario.sarcinelli@ufes.br\\n     Alexandre Santos Brand˜ao\\n     alexandre.brandao@ufv.br\\n\\n1    Graduate Program on Computer Science, Federal University\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\n2    Graduate Program on Electrical Engineering, Federal\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\nranging from face, gesture, movement and speech pattern\\nrecognition, yet much to be developed. There are various\\napplications for robotics such as control – for general mobile\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\nsecurity and surveillance robots [11], home automation [12],\\nin-car recognition and many others, all of which require\\nsome level of interaction with humans, preferably as a two-\\nway conversation [13], [14]. Although efficient, most of the\\nprevious works bases themselves on recognition of phonemes\\nor a small, fixed set of keywords, usually in controlled\\nenvironments, which limits their flexibility and replicability.\\nOur goal is developing a natural, intuitive interface, working\\nas a small conversation between an autonomous robot and\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\nlow-cost solution, unlocking new possibilities for further study\\nand development of better, more autonomous and environment-\\nadaptable robots.\\n                       I. INTRODUCTION\\n   Developing robots capable of autonomously deciding the\\nbest course of action depending on events, environment and\\nuser specifications, are one of the major goals in robotics\\nand correctly perceiving these user’s specifications is critical\\nfor making decisions and acting in the most reasonable way.\\nTherefore a Human-Robot Interface (HRI) capable of both\\nsatisfying the user and performing real time task decision\\nmaking according to environmental changes is a current\\nchallenge.\\n   There are multiple models for HRI, and existing literature\\nsuggests speech recognition is user-friendly, intuitive and\\neffective for various applications [1], [2], [3], [4]. Many\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\nAssistive Robotics.\\n    This paper main contribution is a human–robot interaction frame-\\nwork, having as motivation the development of a Social Assistive\\nRobotics application. The system has easy-to-follow implementation\\nand provides a clear path to be used as a more hands-on approach.\\nIts topics facilitate the teaching tasks, for instance, the description and\\nthe response of an action classifier for a real-world agent. The Artificial\\nNeural Networks (ANN) based classifier relies on dimension reduction\\nto the system’s inputs in order to require a smaller dataset for training.\\nTo achieve it, initially, an external depth sensor provides the skeleton\\njoints features, and then eigenvalues decomposition reduces the input’s\\ndimension. The major insight of the work was the requirement of\\na tiny dataset, being flexible for several applications. In this work,')], 'question': 'what is human robotic', 'web_fallback': True}, 'input': {'messages': [HumanMessage(content='what is human robotic', id='dade212c-8c0f-4577-8b97-d9073549e852')], 'question': None, 'documents': None, 'candidate_answer': None, 'retries': None, 'web_fallback': None}}, 'run_id': '7cd8ec44-788e-475c-9405-d1abf7ef1ca0', 'name': 'document_search', 'tags': ['graph:step:1'], 'metadata': {'langgraph_step': 1, 'langgraph_node': 'document_search', 'langgraph_triggers': ['start:document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_stream', 'run_id': 'e0530f4e-58ac-40f3-8d10-ceb0c50030f2', 'name': 'LangGraph', 'tags': [], 'metadata': {}, 'data': {'chunk': {'document_search': {'question': 'what is human robotic', 'documents': [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\ndedicated to understand, design, and evaluate robotic systems\\nfor use by or with humans” [1]. The interaction can occur in\\ntwo different ways: remote and proximate. They are largely\\ninfluenced by the proximity of the human and the robot.\\nWorks like [2–5] bring good examples of how remote com-\\nmunication can be exploited in several applications, such as\\n\\n\\n\\x02    Kevin Braathen de Carvalho\\n     kevin.carvalho@ufv.br\\n     Daniel Khede Dourado Villa\\n     danielkdv@gmail.com\\n\\n     M´ario Sarcinelli-Filho\\n     mario.sarcinelli@ufes.br\\n     Alexandre Santos Brand˜ao\\n     alexandre.brandao@ufv.br\\n\\n1    Graduate Program on Computer Science, Federal University\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\n2    Graduate Program on Electrical Engineering, Federal\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\nranging from face, gesture, movement and speech pattern\\nrecognition, yet much to be developed. There are various\\napplications for robotics such as control – for general mobile\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\nsecurity and surveillance robots [11], home automation [12],\\nin-car recognition and many others, all of which require\\nsome level of interaction with humans, preferably as a two-\\nway conversation [13], [14]. Although efficient, most of the\\nprevious works bases themselves on recognition of phonemes\\nor a small, fixed set of keywords, usually in controlled\\nenvironments, which limits their flexibility and replicability.\\nOur goal is developing a natural, intuitive interface, working\\nas a small conversation between an autonomous robot and\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\nlow-cost solution, unlocking new possibilities for further study\\nand development of better, more autonomous and environment-\\nadaptable robots.\\n                       I. INTRODUCTION\\n   Developing robots capable of autonomously deciding the\\nbest course of action depending on events, environment and\\nuser specifications, are one of the major goals in robotics\\nand correctly perceiving these user’s specifications is critical\\nfor making decisions and acting in the most reasonable way.\\nTherefore a Human-Robot Interface (HRI) capable of both\\nsatisfying the user and performing real time task decision\\nmaking according to environmental changes is a current\\nchallenge.\\n   There are multiple models for HRI, and existing literature\\nsuggests speech recognition is user-friendly, intuitive and\\neffective for various applications [1], [2], [3], [4]. Many\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\nAssistive Robotics.\\n    This paper main contribution is a human–robot interaction frame-\\nwork, having as motivation the development of a Social Assistive\\nRobotics application. The system has easy-to-follow implementation\\nand provides a clear path to be used as a more hands-on approach.\\nIts topics facilitate the teaching tasks, for instance, the description and\\nthe response of an action classifier for a real-world agent. The Artificial\\nNeural Networks (ANN) based classifier relies on dimension reduction\\nto the system’s inputs in order to require a smaller dataset for training.\\nTo achieve it, initially, an external depth sensor provides the skeleton\\njoints features, and then eigenvalues decomposition reduces the input’s\\ndimension. The major insight of the work was the requirement of\\na tiny dataset, being flexible for several applications. In this work,')], 'web_fallback': True}}}, 'parent_ids': []}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_start', 'data': {}, 'name': 'generate', 'tags': ['graph:step:2'], 'run_id': '04d591cf-bee1-4014-89ed-873d7840078b', 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_start', 'data': {'input': {'context': [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\ndedicated to understand, design, and evaluate robotic systems\\nfor use by or with humans” [1]. The interaction can occur in\\ntwo different ways: remote and proximate. They are largely\\ninfluenced by the proximity of the human and the robot.\\nWorks like [2–5] bring good examples of how remote com-\\nmunication can be exploited in several applications, such as\\n\\n\\n\\x02    Kevin Braathen de Carvalho\\n     kevin.carvalho@ufv.br\\n     Daniel Khede Dourado Villa\\n     danielkdv@gmail.com\\n\\n     M´ario Sarcinelli-Filho\\n     mario.sarcinelli@ufes.br\\n     Alexandre Santos Brand˜ao\\n     alexandre.brandao@ufv.br\\n\\n1    Graduate Program on Computer Science, Federal University\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\n2    Graduate Program on Electrical Engineering, Federal\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\nranging from face, gesture, movement and speech pattern\\nrecognition, yet much to be developed. There are various\\napplications for robotics such as control – for general mobile\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\nsecurity and surveillance robots [11], home automation [12],\\nin-car recognition and many others, all of which require\\nsome level of interaction with humans, preferably as a two-\\nway conversation [13], [14]. Although efficient, most of the\\nprevious works bases themselves on recognition of phonemes\\nor a small, fixed set of keywords, usually in controlled\\nenvironments, which limits their flexibility and replicability.\\nOur goal is developing a natural, intuitive interface, working\\nas a small conversation between an autonomous robot and\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\nlow-cost solution, unlocking new possibilities for further study\\nand development of better, more autonomous and environment-\\nadaptable robots.\\n                       I. INTRODUCTION\\n   Developing robots capable of autonomously deciding the\\nbest course of action depending on events, environment and\\nuser specifications, are one of the major goals in robotics\\nand correctly perceiving these user’s specifications is critical\\nfor making decisions and acting in the most reasonable way.\\nTherefore a Human-Robot Interface (HRI) capable of both\\nsatisfying the user and performing real time task decision\\nmaking according to environmental changes is a current\\nchallenge.\\n   There are multiple models for HRI, and existing literature\\nsuggests speech recognition is user-friendly, intuitive and\\neffective for various applications [1], [2], [3], [4]. Many\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\nAssistive Robotics.\\n    This paper main contribution is a human–robot interaction frame-\\nwork, having as motivation the development of a Social Assistive\\nRobotics application. The system has easy-to-follow implementation\\nand provides a clear path to be used as a more hands-on approach.\\nIts topics facilitate the teaching tasks, for instance, the description and\\nthe response of an action classifier for a real-world agent. The Artificial\\nNeural Networks (ANN) based classifier relies on dimension reduction\\nto the system’s inputs in order to require a smaller dataset for training.\\nTo achieve it, initially, an external depth sensor provides the skeleton\\njoints features, and then eigenvalues decomposition reduces the input’s\\ndimension. The major insight of the work was the requirement of\\na tiny dataset, being flexible for several applications. In this work,')], 'question': 'what is human robotic'}}, 'name': 'RunnableSequence', 'tags': ['seq:step:1'], 'run_id': '08010316-eb96-4b81-95c0-70803f4951e2', 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_prompt_start', 'data': {'input': {'context': [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\ndedicated to understand, design, and evaluate robotic systems\\nfor use by or with humans” [1]. The interaction can occur in\\ntwo different ways: remote and proximate. They are largely\\ninfluenced by the proximity of the human and the robot.\\nWorks like [2–5] bring good examples of how remote com-\\nmunication can be exploited in several applications, such as\\n\\n\\n\\x02    Kevin Braathen de Carvalho\\n     kevin.carvalho@ufv.br\\n     Daniel Khede Dourado Villa\\n     danielkdv@gmail.com\\n\\n     M´ario Sarcinelli-Filho\\n     mario.sarcinelli@ufes.br\\n     Alexandre Santos Brand˜ao\\n     alexandre.brandao@ufv.br\\n\\n1    Graduate Program on Computer Science, Federal University\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\n2    Graduate Program on Electrical Engineering, Federal\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\nranging from face, gesture, movement and speech pattern\\nrecognition, yet much to be developed. There are various\\napplications for robotics such as control – for general mobile\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\nsecurity and surveillance robots [11], home automation [12],\\nin-car recognition and many others, all of which require\\nsome level of interaction with humans, preferably as a two-\\nway conversation [13], [14]. Although efficient, most of the\\nprevious works bases themselves on recognition of phonemes\\nor a small, fixed set of keywords, usually in controlled\\nenvironments, which limits their flexibility and replicability.\\nOur goal is developing a natural, intuitive interface, working\\nas a small conversation between an autonomous robot and\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\nlow-cost solution, unlocking new possibilities for further study\\nand development of better, more autonomous and environment-\\nadaptable robots.\\n                       I. INTRODUCTION\\n   Developing robots capable of autonomously deciding the\\nbest course of action depending on events, environment and\\nuser specifications, are one of the major goals in robotics\\nand correctly perceiving these user’s specifications is critical\\nfor making decisions and acting in the most reasonable way.\\nTherefore a Human-Robot Interface (HRI) capable of both\\nsatisfying the user and performing real time task decision\\nmaking according to environmental changes is a current\\nchallenge.\\n   There are multiple models for HRI, and existing literature\\nsuggests speech recognition is user-friendly, intuitive and\\neffective for various applications [1], [2], [3], [4]. Many\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\nAssistive Robotics.\\n    This paper main contribution is a human–robot interaction frame-\\nwork, having as motivation the development of a Social Assistive\\nRobotics application. The system has easy-to-follow implementation\\nand provides a clear path to be used as a more hands-on approach.\\nIts topics facilitate the teaching tasks, for instance, the description and\\nthe response of an action classifier for a real-world agent. The Artificial\\nNeural Networks (ANN) based classifier relies on dimension reduction\\nto the system’s inputs in order to require a smaller dataset for training.\\nTo achieve it, initially, an external depth sensor provides the skeleton\\njoints features, and then eigenvalues decomposition reduces the input’s\\ndimension. The major insight of the work was the requirement of\\na tiny dataset, being flexible for several applications. In this work,')], 'question': 'what is human robotic'}}, 'name': 'PromptTemplate', 'tags': ['seq:step:1'], 'run_id': 'c5995f94-4337-43bf-acc0-c8392dc797a8', 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_prompt_end', 'data': {'output': StringPromptValue(text=\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.\\nUse three sentences maximum and keep the answer concise \\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\nQuestion: what is human robotic\\nContext: [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\\\ndedicated to understand, design, and evaluate robotic systems\\\\nfor use by or with humans” [1]. The interaction can occur in\\\\ntwo different ways: remote and proximate. They are largely\\\\ninfluenced by the proximity of the human and the robot.\\\\nWorks like [2–5] bring good examples of how remote com-\\\\nmunication can be exploited in several applications, such as\\\\n\\\\n\\\\n\\\\x02    Kevin Braathen de Carvalho\\\\n     kevin.carvalho@ufv.br\\\\n     Daniel Khede Dourado Villa\\\\n     danielkdv@gmail.com\\\\n\\\\n     M´ario Sarcinelli-Filho\\\\n     mario.sarcinelli@ufes.br\\\\n     Alexandre Santos Brand˜ao\\\\n     alexandre.brandao@ufv.br\\\\n\\\\n1    Graduate Program on Computer Science, Federal University\\\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\\\n2    Graduate Program on Electrical Engineering, Federal\\\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\\\nranging from face, gesture, movement and speech pattern\\\\nrecognition, yet much to be developed. There are various\\\\napplications for robotics such as control – for general mobile\\\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\\\nsecurity and surveillance robots [11], home automation [12],\\\\nin-car recognition and many others, all of which require\\\\nsome level of interaction with humans, preferably as a two-\\\\nway conversation [13], [14]. Although efficient, most of the\\\\nprevious works bases themselves on recognition of phonemes\\\\nor a small, fixed set of keywords, usually in controlled\\\\nenvironments, which limits their flexibility and replicability.\\\\nOur goal is developing a natural, intuitive interface, working\\\\nas a small conversation between an autonomous robot and\\\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\\\nlow-cost solution, unlocking new possibilities for further study\\\\nand development of better, more autonomous and environment-\\\\nadaptable robots.\\\\n                       I. INTRODUCTION\\\\n   Developing robots capable of autonomously deciding the\\\\nbest course of action depending on events, environment and\\\\nuser specifications, are one of the major goals in robotics\\\\nand correctly perceiving these user’s specifications is critical\\\\nfor making decisions and acting in the most reasonable way.\\\\nTherefore a Human-Robot Interface (HRI) capable of both\\\\nsatisfying the user and performing real time task decision\\\\nmaking according to environmental changes is a current\\\\nchallenge.\\\\n   There are multiple models for HRI, and existing literature\\\\nsuggests speech recognition is user-friendly, intuitive and\\\\neffective for various applications [1], [2], [3], [4]. Many\\\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\\\nAssistive Robotics.\\\\n    This paper main contribution is a human–robot interaction frame-\\\\nwork, having as motivation the development of a Social Assistive\\\\nRobotics application. The system has easy-to-follow implementation\\\\nand provides a clear path to be used as a more hands-on approach.\\\\nIts topics facilitate the teaching tasks, for instance, the description and\\\\nthe response of an action classifier for a real-world agent. The Artificial\\\\nNeural Networks (ANN) based classifier relies on dimension reduction\\\\nto the system’s inputs in order to require a smaller dataset for training.\\\\nTo achieve it, initially, an external depth sensor provides the skeleton\\\\njoints features, and then eigenvalues decomposition reduces the input’s\\\\ndimension. The major insight of the work was the requirement of\\\\na tiny dataset, being flexible for several applications. In this work,')]\\nAnswer: \\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"), 'input': {'context': [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\ndedicated to understand, design, and evaluate robotic systems\\nfor use by or with humans” [1]. The interaction can occur in\\ntwo different ways: remote and proximate. They are largely\\ninfluenced by the proximity of the human and the robot.\\nWorks like [2–5] bring good examples of how remote com-\\nmunication can be exploited in several applications, such as\\n\\n\\n\\x02    Kevin Braathen de Carvalho\\n     kevin.carvalho@ufv.br\\n     Daniel Khede Dourado Villa\\n     danielkdv@gmail.com\\n\\n     M´ario Sarcinelli-Filho\\n     mario.sarcinelli@ufes.br\\n     Alexandre Santos Brand˜ao\\n     alexandre.brandao@ufv.br\\n\\n1    Graduate Program on Computer Science, Federal University\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\n2    Graduate Program on Electrical Engineering, Federal\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\nranging from face, gesture, movement and speech pattern\\nrecognition, yet much to be developed. There are various\\napplications for robotics such as control – for general mobile\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\nsecurity and surveillance robots [11], home automation [12],\\nin-car recognition and many others, all of which require\\nsome level of interaction with humans, preferably as a two-\\nway conversation [13], [14]. Although efficient, most of the\\nprevious works bases themselves on recognition of phonemes\\nor a small, fixed set of keywords, usually in controlled\\nenvironments, which limits their flexibility and replicability.\\nOur goal is developing a natural, intuitive interface, working\\nas a small conversation between an autonomous robot and\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\nlow-cost solution, unlocking new possibilities for further study\\nand development of better, more autonomous and environment-\\nadaptable robots.\\n                       I. INTRODUCTION\\n   Developing robots capable of autonomously deciding the\\nbest course of action depending on events, environment and\\nuser specifications, are one of the major goals in robotics\\nand correctly perceiving these user’s specifications is critical\\nfor making decisions and acting in the most reasonable way.\\nTherefore a Human-Robot Interface (HRI) capable of both\\nsatisfying the user and performing real time task decision\\nmaking according to environmental changes is a current\\nchallenge.\\n   There are multiple models for HRI, and existing literature\\nsuggests speech recognition is user-friendly, intuitive and\\neffective for various applications [1], [2], [3], [4]. Many\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\nAssistive Robotics.\\n    This paper main contribution is a human–robot interaction frame-\\nwork, having as motivation the development of a Social Assistive\\nRobotics application. The system has easy-to-follow implementation\\nand provides a clear path to be used as a more hands-on approach.\\nIts topics facilitate the teaching tasks, for instance, the description and\\nthe response of an action classifier for a real-world agent. The Artificial\\nNeural Networks (ANN) based classifier relies on dimension reduction\\nto the system’s inputs in order to require a smaller dataset for training.\\nTo achieve it, initially, an external depth sensor provides the skeleton\\njoints features, and then eigenvalues decomposition reduces the input’s\\ndimension. The major insight of the work was the requirement of\\na tiny dataset, being flexible for several applications. In this work,')], 'question': 'what is human robotic'}}, 'run_id': 'c5995f94-4337-43bf-acc0-c8392dc797a8', 'name': 'PromptTemplate', 'tags': ['seq:step:1'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_start', 'data': {'input': {'messages': [[HumanMessage(content=\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.\\nUse three sentences maximum and keep the answer concise \\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\nQuestion: what is human robotic\\nContext: [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\\\ndedicated to understand, design, and evaluate robotic systems\\\\nfor use by or with humans” [1]. The interaction can occur in\\\\ntwo different ways: remote and proximate. They are largely\\\\ninfluenced by the proximity of the human and the robot.\\\\nWorks like [2–5] bring good examples of how remote com-\\\\nmunication can be exploited in several applications, such as\\\\n\\\\n\\\\n\\\\x02    Kevin Braathen de Carvalho\\\\n     kevin.carvalho@ufv.br\\\\n     Daniel Khede Dourado Villa\\\\n     danielkdv@gmail.com\\\\n\\\\n     M´ario Sarcinelli-Filho\\\\n     mario.sarcinelli@ufes.br\\\\n     Alexandre Santos Brand˜ao\\\\n     alexandre.brandao@ufv.br\\\\n\\\\n1    Graduate Program on Computer Science, Federal University\\\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\\\n2    Graduate Program on Electrical Engineering, Federal\\\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\\\nranging from face, gesture, movement and speech pattern\\\\nrecognition, yet much to be developed. There are various\\\\napplications for robotics such as control – for general mobile\\\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\\\nsecurity and surveillance robots [11], home automation [12],\\\\nin-car recognition and many others, all of which require\\\\nsome level of interaction with humans, preferably as a two-\\\\nway conversation [13], [14]. Although efficient, most of the\\\\nprevious works bases themselves on recognition of phonemes\\\\nor a small, fixed set of keywords, usually in controlled\\\\nenvironments, which limits their flexibility and replicability.\\\\nOur goal is developing a natural, intuitive interface, working\\\\nas a small conversation between an autonomous robot and\\\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\\\nlow-cost solution, unlocking new possibilities for further study\\\\nand development of better, more autonomous and environment-\\\\nadaptable robots.\\\\n                       I. INTRODUCTION\\\\n   Developing robots capable of autonomously deciding the\\\\nbest course of action depending on events, environment and\\\\nuser specifications, are one of the major goals in robotics\\\\nand correctly perceiving these user’s specifications is critical\\\\nfor making decisions and acting in the most reasonable way.\\\\nTherefore a Human-Robot Interface (HRI) capable of both\\\\nsatisfying the user and performing real time task decision\\\\nmaking according to environmental changes is a current\\\\nchallenge.\\\\n   There are multiple models for HRI, and existing literature\\\\nsuggests speech recognition is user-friendly, intuitive and\\\\neffective for various applications [1], [2], [3], [4]. Many\\\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\\\nAssistive Robotics.\\\\n    This paper main contribution is a human–robot interaction frame-\\\\nwork, having as motivation the development of a Social Assistive\\\\nRobotics application. The system has easy-to-follow implementation\\\\nand provides a clear path to be used as a more hands-on approach.\\\\nIts topics facilitate the teaching tasks, for instance, the description and\\\\nthe response of an action classifier for a real-world agent. The Artificial\\\\nNeural Networks (ANN) based classifier relies on dimension reduction\\\\nto the system’s inputs in order to require a smaller dataset for training.\\\\nTo achieve it, initially, an external depth sensor provides the skeleton\\\\njoints features, and then eigenvalues decomposition reduces the input’s\\\\ndimension. The major insight of the work was the requirement of\\\\na tiny dataset, being flexible for several applications. In this work,')]\\nAnswer: \\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\")]]}}, 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='Human', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      "Human-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='-', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      "--*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='robot', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      "robot-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' interaction', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " interaction-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' (', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " (-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='H', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      "H-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='RI', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      "RI-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=')', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      ")-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' is', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " is-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' a', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " a-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' field', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " field-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' of', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " of-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' study', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " study-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' dedicated', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " dedicated-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' to', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " to-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' understanding', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " understanding-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=',', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      ",-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' designing', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " designing-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=',', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      ",-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' and', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " and-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' evaluating', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " evaluating-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' robotic', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " robotic-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' systems', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " systems-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' for', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " for-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' use', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " use-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' by', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " by-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' or', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " or-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' with', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " with-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' humans', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      " humans-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='.', id='run-58b6b617-2461-49fc-98ba-288455ea2651')}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      ".-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', response_metadata={'finish_reason': 'stop'}, id='run-58b6b617-2461-49fc-98ba-288455ea2651', usage_metadata={'input_tokens': 1267, 'output_tokens': 31, 'total_tokens': 1298})}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_end', 'data': {'output': AIMessage(content='Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.', response_metadata={'finish_reason': 'stop'}, id='run-58b6b617-2461-49fc-98ba-288455ea2651', usage_metadata={'input_tokens': 1267, 'output_tokens': 31, 'total_tokens': 1298}), 'input': {'messages': [[HumanMessage(content=\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.\\nUse three sentences maximum and keep the answer concise \\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\nQuestion: what is human robotic\\nContext: [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\\\ndedicated to understand, design, and evaluate robotic systems\\\\nfor use by or with humans” [1]. The interaction can occur in\\\\ntwo different ways: remote and proximate. They are largely\\\\ninfluenced by the proximity of the human and the robot.\\\\nWorks like [2–5] bring good examples of how remote com-\\\\nmunication can be exploited in several applications, such as\\\\n\\\\n\\\\n\\\\x02    Kevin Braathen de Carvalho\\\\n     kevin.carvalho@ufv.br\\\\n     Daniel Khede Dourado Villa\\\\n     danielkdv@gmail.com\\\\n\\\\n     M´ario Sarcinelli-Filho\\\\n     mario.sarcinelli@ufes.br\\\\n     Alexandre Santos Brand˜ao\\\\n     alexandre.brandao@ufv.br\\\\n\\\\n1    Graduate Program on Computer Science, Federal University\\\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\\\n2    Graduate Program on Electrical Engineering, Federal\\\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\\\nranging from face, gesture, movement and speech pattern\\\\nrecognition, yet much to be developed. There are various\\\\napplications for robotics such as control – for general mobile\\\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\\\nsecurity and surveillance robots [11], home automation [12],\\\\nin-car recognition and many others, all of which require\\\\nsome level of interaction with humans, preferably as a two-\\\\nway conversation [13], [14]. Although efficient, most of the\\\\nprevious works bases themselves on recognition of phonemes\\\\nor a small, fixed set of keywords, usually in controlled\\\\nenvironments, which limits their flexibility and replicability.\\\\nOur goal is developing a natural, intuitive interface, working\\\\nas a small conversation between an autonomous robot and\\\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\\\nlow-cost solution, unlocking new possibilities for further study\\\\nand development of better, more autonomous and environment-\\\\nadaptable robots.\\\\n                       I. INTRODUCTION\\\\n   Developing robots capable of autonomously deciding the\\\\nbest course of action depending on events, environment and\\\\nuser specifications, are one of the major goals in robotics\\\\nand correctly perceiving these user’s specifications is critical\\\\nfor making decisions and acting in the most reasonable way.\\\\nTherefore a Human-Robot Interface (HRI) capable of both\\\\nsatisfying the user and performing real time task decision\\\\nmaking according to environmental changes is a current\\\\nchallenge.\\\\n   There are multiple models for HRI, and existing literature\\\\nsuggests speech recognition is user-friendly, intuitive and\\\\neffective for various applications [1], [2], [3], [4]. Many\\\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\\\nAssistive Robotics.\\\\n    This paper main contribution is a human–robot interaction frame-\\\\nwork, having as motivation the development of a Social Assistive\\\\nRobotics application. The system has easy-to-follow implementation\\\\nand provides a clear path to be used as a more hands-on approach.\\\\nIts topics facilitate the teaching tasks, for instance, the description and\\\\nthe response of an action classifier for a real-world agent. The Artificial\\\\nNeural Networks (ANN) based classifier relies on dimension reduction\\\\nto the system’s inputs in order to require a smaller dataset for training.\\\\nTo achieve it, initially, an external depth sensor provides the skeleton\\\\njoints features, and then eigenvalues decomposition reduces the input’s\\\\ndimension. The major insight of the work was the requirement of\\\\na tiny dataset, being flexible for several applications. In this work,')]\\nAnswer: \\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\")]]}}, 'run_id': '58b6b617-2461-49fc-98ba-288455ea2651', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_parser_start', 'data': {'input': AIMessage(content='Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.', response_metadata={'finish_reason': 'stop'}, id='run-58b6b617-2461-49fc-98ba-288455ea2651', usage_metadata={'input_tokens': 1267, 'output_tokens': 31, 'total_tokens': 1298})}, 'name': 'StrOutputParser', 'tags': ['seq:step:3'], 'run_id': 'fed5bae4-48d1-4ee0-9f6f-86265db5e39f', 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_parser_end', 'data': {'output': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.', 'input': AIMessage(content='Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.', response_metadata={'finish_reason': 'stop'}, id='run-58b6b617-2461-49fc-98ba-288455ea2651', usage_metadata={'input_tokens': 1267, 'output_tokens': 31, 'total_tokens': 1298})}, 'run_id': 'fed5bae4-48d1-4ee0-9f6f-86265db5e39f', 'name': 'StrOutputParser', 'tags': ['seq:step:3'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', '08010316-eb96-4b81-95c0-70803f4951e2']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_end', 'data': {'output': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.', 'input': {'context': [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\ndedicated to understand, design, and evaluate robotic systems\\nfor use by or with humans” [1]. The interaction can occur in\\ntwo different ways: remote and proximate. They are largely\\ninfluenced by the proximity of the human and the robot.\\nWorks like [2–5] bring good examples of how remote com-\\nmunication can be exploited in several applications, such as\\n\\n\\n\\x02    Kevin Braathen de Carvalho\\n     kevin.carvalho@ufv.br\\n     Daniel Khede Dourado Villa\\n     danielkdv@gmail.com\\n\\n     M´ario Sarcinelli-Filho\\n     mario.sarcinelli@ufes.br\\n     Alexandre Santos Brand˜ao\\n     alexandre.brandao@ufv.br\\n\\n1    Graduate Program on Computer Science, Federal University\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\n2    Graduate Program on Electrical Engineering, Federal\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\nranging from face, gesture, movement and speech pattern\\nrecognition, yet much to be developed. There are various\\napplications for robotics such as control – for general mobile\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\nsecurity and surveillance robots [11], home automation [12],\\nin-car recognition and many others, all of which require\\nsome level of interaction with humans, preferably as a two-\\nway conversation [13], [14]. Although efficient, most of the\\nprevious works bases themselves on recognition of phonemes\\nor a small, fixed set of keywords, usually in controlled\\nenvironments, which limits their flexibility and replicability.\\nOur goal is developing a natural, intuitive interface, working\\nas a small conversation between an autonomous robot and\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\nlow-cost solution, unlocking new possibilities for further study\\nand development of better, more autonomous and environment-\\nadaptable robots.\\n                       I. INTRODUCTION\\n   Developing robots capable of autonomously deciding the\\nbest course of action depending on events, environment and\\nuser specifications, are one of the major goals in robotics\\nand correctly perceiving these user’s specifications is critical\\nfor making decisions and acting in the most reasonable way.\\nTherefore a Human-Robot Interface (HRI) capable of both\\nsatisfying the user and performing real time task decision\\nmaking according to environmental changes is a current\\nchallenge.\\n   There are multiple models for HRI, and existing literature\\nsuggests speech recognition is user-friendly, intuitive and\\neffective for various applications [1], [2], [3], [4]. Many\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\nAssistive Robotics.\\n    This paper main contribution is a human–robot interaction frame-\\nwork, having as motivation the development of a Social Assistive\\nRobotics application. The system has easy-to-follow implementation\\nand provides a clear path to be used as a more hands-on approach.\\nIts topics facilitate the teaching tasks, for instance, the description and\\nthe response of an action classifier for a real-world agent. The Artificial\\nNeural Networks (ANN) based classifier relies on dimension reduction\\nto the system’s inputs in order to require a smaller dataset for training.\\nTo achieve it, initially, an external depth sensor provides the skeleton\\njoints features, and then eigenvalues decomposition reduces the input’s\\ndimension. The major insight of the work was the requirement of\\na tiny dataset, being flexible for several applications. In this work,')], 'question': 'what is human robotic'}}, 'run_id': '08010316-eb96-4b81-95c0-70803f4951e2', 'name': 'RunnableSequence', 'tags': ['seq:step:1'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_start', 'data': {'input': {'retries': 0, 'candidate_answer': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.'}}, 'name': 'ChannelWrite<generate,messages,question,documents,candidate_answer,retries,web_fallback>', 'tags': ['seq:step:2', 'langsmith:hidden'], 'run_id': '18844ceb-ea70-43fa-8b64-b07a6f42609c', 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_end', 'data': {'output': {'retries': 0, 'candidate_answer': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.'}, 'input': {'retries': 0, 'candidate_answer': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.'}}, 'run_id': '18844ceb-ea70-43fa-8b64-b07a6f42609c', 'name': 'ChannelWrite<generate,messages,question,documents,candidate_answer,retries,web_fallback>', 'tags': ['seq:step:2', 'langsmith:hidden'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_start', 'data': {'input': {'retries': 0, 'candidate_answer': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.', 'messages': [HumanMessage(content='what is human robotic', id='dade212c-8c0f-4577-8b97-d9073549e852')], 'question': 'what is human robotic', 'documents': [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\ndedicated to understand, design, and evaluate robotic systems\\nfor use by or with humans” [1]. The interaction can occur in\\ntwo different ways: remote and proximate. They are largely\\ninfluenced by the proximity of the human and the robot.\\nWorks like [2–5] bring good examples of how remote com-\\nmunication can be exploited in several applications, such as\\n\\n\\n\\x02    Kevin Braathen de Carvalho\\n     kevin.carvalho@ufv.br\\n     Daniel Khede Dourado Villa\\n     danielkdv@gmail.com\\n\\n     M´ario Sarcinelli-Filho\\n     mario.sarcinelli@ufes.br\\n     Alexandre Santos Brand˜ao\\n     alexandre.brandao@ufv.br\\n\\n1    Graduate Program on Computer Science, Federal University\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\n2    Graduate Program on Electrical Engineering, Federal\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\nranging from face, gesture, movement and speech pattern\\nrecognition, yet much to be developed. There are various\\napplications for robotics such as control – for general mobile\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\nsecurity and surveillance robots [11], home automation [12],\\nin-car recognition and many others, all of which require\\nsome level of interaction with humans, preferably as a two-\\nway conversation [13], [14]. Although efficient, most of the\\nprevious works bases themselves on recognition of phonemes\\nor a small, fixed set of keywords, usually in controlled\\nenvironments, which limits their flexibility and replicability.\\nOur goal is developing a natural, intuitive interface, working\\nas a small conversation between an autonomous robot and\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\nlow-cost solution, unlocking new possibilities for further study\\nand development of better, more autonomous and environment-\\nadaptable robots.\\n                       I. INTRODUCTION\\n   Developing robots capable of autonomously deciding the\\nbest course of action depending on events, environment and\\nuser specifications, are one of the major goals in robotics\\nand correctly perceiving these user’s specifications is critical\\nfor making decisions and acting in the most reasonable way.\\nTherefore a Human-Robot Interface (HRI) capable of both\\nsatisfying the user and performing real time task decision\\nmaking according to environmental changes is a current\\nchallenge.\\n   There are multiple models for HRI, and existing literature\\nsuggests speech recognition is user-friendly, intuitive and\\neffective for various applications [1], [2], [3], [4]. Many\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\nAssistive Robotics.\\n    This paper main contribution is a human–robot interaction frame-\\nwork, having as motivation the development of a Social Assistive\\nRobotics application. The system has easy-to-follow implementation\\nand provides a clear path to be used as a more hands-on approach.\\nIts topics facilitate the teaching tasks, for instance, the description and\\nthe response of an action classifier for a real-world agent. The Artificial\\nNeural Networks (ANN) based classifier relies on dimension reduction\\nto the system’s inputs in order to require a smaller dataset for training.\\nTo achieve it, initially, an external depth sensor provides the skeleton\\njoints features, and then eigenvalues decomposition reduces the input’s\\ndimension. The major insight of the work was the requirement of\\na tiny dataset, being flexible for several applications. In this work,')], 'web_fallback': True}}, 'name': 'grade_generation_v_documents_and_question', 'tags': ['seq:step:3'], 'run_id': 'b5c93b09-a50a-44cd-b6f9-727ec439b437', 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_start', 'data': {'input': {'documents': [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\ndedicated to understand, design, and evaluate robotic systems\\nfor use by or with humans” [1]. The interaction can occur in\\ntwo different ways: remote and proximate. They are largely\\ninfluenced by the proximity of the human and the robot.\\nWorks like [2–5] bring good examples of how remote com-\\nmunication can be exploited in several applications, such as\\n\\n\\n\\x02    Kevin Braathen de Carvalho\\n     kevin.carvalho@ufv.br\\n     Daniel Khede Dourado Villa\\n     danielkdv@gmail.com\\n\\n     M´ario Sarcinelli-Filho\\n     mario.sarcinelli@ufes.br\\n     Alexandre Santos Brand˜ao\\n     alexandre.brandao@ufv.br\\n\\n1    Graduate Program on Computer Science, Federal University\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\n2    Graduate Program on Electrical Engineering, Federal\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\nranging from face, gesture, movement and speech pattern\\nrecognition, yet much to be developed. There are various\\napplications for robotics such as control – for general mobile\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\nsecurity and surveillance robots [11], home automation [12],\\nin-car recognition and many others, all of which require\\nsome level of interaction with humans, preferably as a two-\\nway conversation [13], [14]. Although efficient, most of the\\nprevious works bases themselves on recognition of phonemes\\nor a small, fixed set of keywords, usually in controlled\\nenvironments, which limits their flexibility and replicability.\\nOur goal is developing a natural, intuitive interface, working\\nas a small conversation between an autonomous robot and\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\nlow-cost solution, unlocking new possibilities for further study\\nand development of better, more autonomous and environment-\\nadaptable robots.\\n                       I. INTRODUCTION\\n   Developing robots capable of autonomously deciding the\\nbest course of action depending on events, environment and\\nuser specifications, are one of the major goals in robotics\\nand correctly perceiving these user’s specifications is critical\\nfor making decisions and acting in the most reasonable way.\\nTherefore a Human-Robot Interface (HRI) capable of both\\nsatisfying the user and performing real time task decision\\nmaking according to environmental changes is a current\\nchallenge.\\n   There are multiple models for HRI, and existing literature\\nsuggests speech recognition is user-friendly, intuitive and\\neffective for various applications [1], [2], [3], [4]. Many\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\nAssistive Robotics.\\n    This paper main contribution is a human–robot interaction frame-\\nwork, having as motivation the development of a Social Assistive\\nRobotics application. The system has easy-to-follow implementation\\nand provides a clear path to be used as a more hands-on approach.\\nIts topics facilitate the teaching tasks, for instance, the description and\\nthe response of an action classifier for a real-world agent. The Artificial\\nNeural Networks (ANN) based classifier relies on dimension reduction\\nto the system’s inputs in order to require a smaller dataset for training.\\nTo achieve it, initially, an external depth sensor provides the skeleton\\njoints features, and then eigenvalues decomposition reduces the input’s\\ndimension. The major insight of the work was the requirement of\\na tiny dataset, being flexible for several applications. In this work,')], 'generation': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.'}}, 'name': 'RunnableSequence', 'tags': [], 'run_id': 'b8b803a0-fd70-43b7-bb8d-9a086c0880be', 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', 'b5c93b09-a50a-44cd-b6f9-727ec439b437']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_prompt_start', 'data': {'input': {'documents': [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\ndedicated to understand, design, and evaluate robotic systems\\nfor use by or with humans” [1]. The interaction can occur in\\ntwo different ways: remote and proximate. They are largely\\ninfluenced by the proximity of the human and the robot.\\nWorks like [2–5] bring good examples of how remote com-\\nmunication can be exploited in several applications, such as\\n\\n\\n\\x02    Kevin Braathen de Carvalho\\n     kevin.carvalho@ufv.br\\n     Daniel Khede Dourado Villa\\n     danielkdv@gmail.com\\n\\n     M´ario Sarcinelli-Filho\\n     mario.sarcinelli@ufes.br\\n     Alexandre Santos Brand˜ao\\n     alexandre.brandao@ufv.br\\n\\n1    Graduate Program on Computer Science, Federal University\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\n2    Graduate Program on Electrical Engineering, Federal\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\nranging from face, gesture, movement and speech pattern\\nrecognition, yet much to be developed. There are various\\napplications for robotics such as control – for general mobile\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\nsecurity and surveillance robots [11], home automation [12],\\nin-car recognition and many others, all of which require\\nsome level of interaction with humans, preferably as a two-\\nway conversation [13], [14]. Although efficient, most of the\\nprevious works bases themselves on recognition of phonemes\\nor a small, fixed set of keywords, usually in controlled\\nenvironments, which limits their flexibility and replicability.\\nOur goal is developing a natural, intuitive interface, working\\nas a small conversation between an autonomous robot and\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\nlow-cost solution, unlocking new possibilities for further study\\nand development of better, more autonomous and environment-\\nadaptable robots.\\n                       I. INTRODUCTION\\n   Developing robots capable of autonomously deciding the\\nbest course of action depending on events, environment and\\nuser specifications, are one of the major goals in robotics\\nand correctly perceiving these user’s specifications is critical\\nfor making decisions and acting in the most reasonable way.\\nTherefore a Human-Robot Interface (HRI) capable of both\\nsatisfying the user and performing real time task decision\\nmaking according to environmental changes is a current\\nchallenge.\\n   There are multiple models for HRI, and existing literature\\nsuggests speech recognition is user-friendly, intuitive and\\neffective for various applications [1], [2], [3], [4]. Many\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\nAssistive Robotics.\\n    This paper main contribution is a human–robot interaction frame-\\nwork, having as motivation the development of a Social Assistive\\nRobotics application. The system has easy-to-follow implementation\\nand provides a clear path to be used as a more hands-on approach.\\nIts topics facilitate the teaching tasks, for instance, the description and\\nthe response of an action classifier for a real-world agent. The Artificial\\nNeural Networks (ANN) based classifier relies on dimension reduction\\nto the system’s inputs in order to require a smaller dataset for training.\\nTo achieve it, initially, an external depth sensor provides the skeleton\\njoints features, and then eigenvalues decomposition reduces the input’s\\ndimension. The major insight of the work was the requirement of\\na tiny dataset, being flexible for several applications. In this work,')], 'generation': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.'}}, 'name': 'PromptTemplate', 'tags': ['seq:step:1'], 'run_id': '05027fc9-3957-4988-b108-de0a6d1f37ed', 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', 'b5c93b09-a50a-44cd-b6f9-727ec439b437', 'b8b803a0-fd70-43b7-bb8d-9a086c0880be']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_prompt_end', 'data': {'output': StringPromptValue(text=\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts.\\nGive a binary score 'yes' or 'no', where 'yes' means that the answer is grounded in / supported by the set of facts.\\n\\nIF the generation includes code examples, make sure those examples are FULLY present in the set of facts, otherwise always return score 'no'. \\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\nSet of facts: \\n\\n [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\\\ndedicated to understand, design, and evaluate robotic systems\\\\nfor use by or with humans” [1]. The interaction can occur in\\\\ntwo different ways: remote and proximate. They are largely\\\\ninfluenced by the proximity of the human and the robot.\\\\nWorks like [2–5] bring good examples of how remote com-\\\\nmunication can be exploited in several applications, such as\\\\n\\\\n\\\\n\\\\x02    Kevin Braathen de Carvalho\\\\n     kevin.carvalho@ufv.br\\\\n     Daniel Khede Dourado Villa\\\\n     danielkdv@gmail.com\\\\n\\\\n     M´ario Sarcinelli-Filho\\\\n     mario.sarcinelli@ufes.br\\\\n     Alexandre Santos Brand˜ao\\\\n     alexandre.brandao@ufv.br\\\\n\\\\n1    Graduate Program on Computer Science, Federal University\\\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\\\n2    Graduate Program on Electrical Engineering, Federal\\\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\\\nranging from face, gesture, movement and speech pattern\\\\nrecognition, yet much to be developed. There are various\\\\napplications for robotics such as control – for general mobile\\\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\\\nsecurity and surveillance robots [11], home automation [12],\\\\nin-car recognition and many others, all of which require\\\\nsome level of interaction with humans, preferably as a two-\\\\nway conversation [13], [14]. Although efficient, most of the\\\\nprevious works bases themselves on recognition of phonemes\\\\nor a small, fixed set of keywords, usually in controlled\\\\nenvironments, which limits their flexibility and replicability.\\\\nOur goal is developing a natural, intuitive interface, working\\\\nas a small conversation between an autonomous robot and\\\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\\\nlow-cost solution, unlocking new possibilities for further study\\\\nand development of better, more autonomous and environment-\\\\nadaptable robots.\\\\n                       I. INTRODUCTION\\\\n   Developing robots capable of autonomously deciding the\\\\nbest course of action depending on events, environment and\\\\nuser specifications, are one of the major goals in robotics\\\\nand correctly perceiving these user’s specifications is critical\\\\nfor making decisions and acting in the most reasonable way.\\\\nTherefore a Human-Robot Interface (HRI) capable of both\\\\nsatisfying the user and performing real time task decision\\\\nmaking according to environmental changes is a current\\\\nchallenge.\\\\n   There are multiple models for HRI, and existing literature\\\\nsuggests speech recognition is user-friendly, intuitive and\\\\neffective for various applications [1], [2], [3], [4]. Many\\\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\\\nAssistive Robotics.\\\\n    This paper main contribution is a human–robot interaction frame-\\\\nwork, having as motivation the development of a Social Assistive\\\\nRobotics application. The system has easy-to-follow implementation\\\\nand provides a clear path to be used as a more hands-on approach.\\\\nIts topics facilitate the teaching tasks, for instance, the description and\\\\nthe response of an action classifier for a real-world agent. The Artificial\\\\nNeural Networks (ANN) based classifier relies on dimension reduction\\\\nto the system’s inputs in order to require a smaller dataset for training.\\\\nTo achieve it, initially, an external depth sensor provides the skeleton\\\\njoints features, and then eigenvalues decomposition reduces the input’s\\\\ndimension. The major insight of the work was the requirement of\\\\na tiny dataset, being flexible for several applications. In this work,')] \\n\\n LLM generation: Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"), 'input': {'documents': [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\ndedicated to understand, design, and evaluate robotic systems\\nfor use by or with humans” [1]. The interaction can occur in\\ntwo different ways: remote and proximate. They are largely\\ninfluenced by the proximity of the human and the robot.\\nWorks like [2–5] bring good examples of how remote com-\\nmunication can be exploited in several applications, such as\\n\\n\\n\\x02    Kevin Braathen de Carvalho\\n     kevin.carvalho@ufv.br\\n     Daniel Khede Dourado Villa\\n     danielkdv@gmail.com\\n\\n     M´ario Sarcinelli-Filho\\n     mario.sarcinelli@ufes.br\\n     Alexandre Santos Brand˜ao\\n     alexandre.brandao@ufv.br\\n\\n1    Graduate Program on Computer Science, Federal University\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\n2    Graduate Program on Electrical Engineering, Federal\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\nranging from face, gesture, movement and speech pattern\\nrecognition, yet much to be developed. There are various\\napplications for robotics such as control – for general mobile\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\nsecurity and surveillance robots [11], home automation [12],\\nin-car recognition and many others, all of which require\\nsome level of interaction with humans, preferably as a two-\\nway conversation [13], [14]. Although efficient, most of the\\nprevious works bases themselves on recognition of phonemes\\nor a small, fixed set of keywords, usually in controlled\\nenvironments, which limits their flexibility and replicability.\\nOur goal is developing a natural, intuitive interface, working\\nas a small conversation between an autonomous robot and\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\nlow-cost solution, unlocking new possibilities for further study\\nand development of better, more autonomous and environment-\\nadaptable robots.\\n                       I. INTRODUCTION\\n   Developing robots capable of autonomously deciding the\\nbest course of action depending on events, environment and\\nuser specifications, are one of the major goals in robotics\\nand correctly perceiving these user’s specifications is critical\\nfor making decisions and acting in the most reasonable way.\\nTherefore a Human-Robot Interface (HRI) capable of both\\nsatisfying the user and performing real time task decision\\nmaking according to environmental changes is a current\\nchallenge.\\n   There are multiple models for HRI, and existing literature\\nsuggests speech recognition is user-friendly, intuitive and\\neffective for various applications [1], [2], [3], [4]. Many\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\nAssistive Robotics.\\n    This paper main contribution is a human–robot interaction frame-\\nwork, having as motivation the development of a Social Assistive\\nRobotics application. The system has easy-to-follow implementation\\nand provides a clear path to be used as a more hands-on approach.\\nIts topics facilitate the teaching tasks, for instance, the description and\\nthe response of an action classifier for a real-world agent. The Artificial\\nNeural Networks (ANN) based classifier relies on dimension reduction\\nto the system’s inputs in order to require a smaller dataset for training.\\nTo achieve it, initially, an external depth sensor provides the skeleton\\njoints features, and then eigenvalues decomposition reduces the input’s\\ndimension. The major insight of the work was the requirement of\\na tiny dataset, being flexible for several applications. In this work,')], 'generation': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.'}}, 'run_id': '05027fc9-3957-4988-b108-de0a6d1f37ed', 'name': 'PromptTemplate', 'tags': ['seq:step:1'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', 'b5c93b09-a50a-44cd-b6f9-727ec439b437', 'b8b803a0-fd70-43b7-bb8d-9a086c0880be']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_start', 'data': {'input': {'messages': [[HumanMessage(content=\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts.\\nGive a binary score 'yes' or 'no', where 'yes' means that the answer is grounded in / supported by the set of facts.\\n\\nIF the generation includes code examples, make sure those examples are FULLY present in the set of facts, otherwise always return score 'no'. \\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\nSet of facts: \\n\\n [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\\\ndedicated to understand, design, and evaluate robotic systems\\\\nfor use by or with humans” [1]. The interaction can occur in\\\\ntwo different ways: remote and proximate. They are largely\\\\ninfluenced by the proximity of the human and the robot.\\\\nWorks like [2–5] bring good examples of how remote com-\\\\nmunication can be exploited in several applications, such as\\\\n\\\\n\\\\n\\\\x02    Kevin Braathen de Carvalho\\\\n     kevin.carvalho@ufv.br\\\\n     Daniel Khede Dourado Villa\\\\n     danielkdv@gmail.com\\\\n\\\\n     M´ario Sarcinelli-Filho\\\\n     mario.sarcinelli@ufes.br\\\\n     Alexandre Santos Brand˜ao\\\\n     alexandre.brandao@ufv.br\\\\n\\\\n1    Graduate Program on Computer Science, Federal University\\\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\\\n2    Graduate Program on Electrical Engineering, Federal\\\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\\\nranging from face, gesture, movement and speech pattern\\\\nrecognition, yet much to be developed. There are various\\\\napplications for robotics such as control – for general mobile\\\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\\\nsecurity and surveillance robots [11], home automation [12],\\\\nin-car recognition and many others, all of which require\\\\nsome level of interaction with humans, preferably as a two-\\\\nway conversation [13], [14]. Although efficient, most of the\\\\nprevious works bases themselves on recognition of phonemes\\\\nor a small, fixed set of keywords, usually in controlled\\\\nenvironments, which limits their flexibility and replicability.\\\\nOur goal is developing a natural, intuitive interface, working\\\\nas a small conversation between an autonomous robot and\\\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\\\nlow-cost solution, unlocking new possibilities for further study\\\\nand development of better, more autonomous and environment-\\\\nadaptable robots.\\\\n                       I. INTRODUCTION\\\\n   Developing robots capable of autonomously deciding the\\\\nbest course of action depending on events, environment and\\\\nuser specifications, are one of the major goals in robotics\\\\nand correctly perceiving these user’s specifications is critical\\\\nfor making decisions and acting in the most reasonable way.\\\\nTherefore a Human-Robot Interface (HRI) capable of both\\\\nsatisfying the user and performing real time task decision\\\\nmaking according to environmental changes is a current\\\\nchallenge.\\\\n   There are multiple models for HRI, and existing literature\\\\nsuggests speech recognition is user-friendly, intuitive and\\\\neffective for various applications [1], [2], [3], [4]. Many\\\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\\\nAssistive Robotics.\\\\n    This paper main contribution is a human–robot interaction frame-\\\\nwork, having as motivation the development of a Social Assistive\\\\nRobotics application. The system has easy-to-follow implementation\\\\nand provides a clear path to be used as a more hands-on approach.\\\\nIts topics facilitate the teaching tasks, for instance, the description and\\\\nthe response of an action classifier for a real-world agent. The Artificial\\\\nNeural Networks (ANN) based classifier relies on dimension reduction\\\\nto the system’s inputs in order to require a smaller dataset for training.\\\\nTo achieve it, initially, an external depth sensor provides the skeleton\\\\njoints features, and then eigenvalues decomposition reduces the input’s\\\\ndimension. The major insight of the work was the requirement of\\\\na tiny dataset, being flexible for several applications. In this work,')] \\n\\n LLM generation: Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\")]]}}, 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'run_id': '0e2600e5-1afc-46c2-aa48-87e926234b06', 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', 'b5c93b09-a50a-44cd-b6f9-727ec439b437', 'b8b803a0-fd70-43b7-bb8d-9a086c0880be']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_kx9v', 'function': {'arguments': '{\"binary_score\":\"yes\"}', 'name': 'GradeHallucinations'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0e2600e5-1afc-46c2-aa48-87e926234b06', tool_calls=[{'name': 'GradeHallucinations', 'args': {'binary_score': 'yes'}, 'id': 'call_kx9v'}], usage_metadata={'input_tokens': 2146, 'output_tokens': 69, 'total_tokens': 2215}, tool_call_chunks=[{'name': 'GradeHallucinations', 'args': '{\"binary_score\":\"yes\"}', 'id': 'call_kx9v', 'index': None}])}, 'run_id': '0e2600e5-1afc-46c2-aa48-87e926234b06', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', 'b5c93b09-a50a-44cd-b6f9-727ec439b437', 'b8b803a0-fd70-43b7-bb8d-9a086c0880be']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_end', 'data': {'output': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_kx9v', 'function': {'arguments': '{\"binary_score\":\"yes\"}', 'name': 'GradeHallucinations'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0e2600e5-1afc-46c2-aa48-87e926234b06', tool_calls=[{'name': 'GradeHallucinations', 'args': {'binary_score': 'yes'}, 'id': 'call_kx9v'}], usage_metadata={'input_tokens': 2146, 'output_tokens': 69, 'total_tokens': 2215}), 'input': {'messages': [[HumanMessage(content=\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts.\\nGive a binary score 'yes' or 'no', where 'yes' means that the answer is grounded in / supported by the set of facts.\\n\\nIF the generation includes code examples, make sure those examples are FULLY present in the set of facts, otherwise always return score 'no'. \\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\nSet of facts: \\n\\n [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\\\ndedicated to understand, design, and evaluate robotic systems\\\\nfor use by or with humans” [1]. The interaction can occur in\\\\ntwo different ways: remote and proximate. They are largely\\\\ninfluenced by the proximity of the human and the robot.\\\\nWorks like [2–5] bring good examples of how remote com-\\\\nmunication can be exploited in several applications, such as\\\\n\\\\n\\\\n\\\\x02    Kevin Braathen de Carvalho\\\\n     kevin.carvalho@ufv.br\\\\n     Daniel Khede Dourado Villa\\\\n     danielkdv@gmail.com\\\\n\\\\n     M´ario Sarcinelli-Filho\\\\n     mario.sarcinelli@ufes.br\\\\n     Alexandre Santos Brand˜ao\\\\n     alexandre.brandao@ufv.br\\\\n\\\\n1    Graduate Program on Computer Science, Federal University\\\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\\\n2    Graduate Program on Electrical Engineering, Federal\\\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\\\nranging from face, gesture, movement and speech pattern\\\\nrecognition, yet much to be developed. There are various\\\\napplications for robotics such as control – for general mobile\\\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\\\nsecurity and surveillance robots [11], home automation [12],\\\\nin-car recognition and many others, all of which require\\\\nsome level of interaction with humans, preferably as a two-\\\\nway conversation [13], [14]. Although efficient, most of the\\\\nprevious works bases themselves on recognition of phonemes\\\\nor a small, fixed set of keywords, usually in controlled\\\\nenvironments, which limits their flexibility and replicability.\\\\nOur goal is developing a natural, intuitive interface, working\\\\nas a small conversation between an autonomous robot and\\\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\\\nlow-cost solution, unlocking new possibilities for further study\\\\nand development of better, more autonomous and environment-\\\\nadaptable robots.\\\\n                       I. INTRODUCTION\\\\n   Developing robots capable of autonomously deciding the\\\\nbest course of action depending on events, environment and\\\\nuser specifications, are one of the major goals in robotics\\\\nand correctly perceiving these user’s specifications is critical\\\\nfor making decisions and acting in the most reasonable way.\\\\nTherefore a Human-Robot Interface (HRI) capable of both\\\\nsatisfying the user and performing real time task decision\\\\nmaking according to environmental changes is a current\\\\nchallenge.\\\\n   There are multiple models for HRI, and existing literature\\\\nsuggests speech recognition is user-friendly, intuitive and\\\\neffective for various applications [1], [2], [3], [4]. Many\\\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\\\nAssistive Robotics.\\\\n    This paper main contribution is a human–robot interaction frame-\\\\nwork, having as motivation the development of a Social Assistive\\\\nRobotics application. The system has easy-to-follow implementation\\\\nand provides a clear path to be used as a more hands-on approach.\\\\nIts topics facilitate the teaching tasks, for instance, the description and\\\\nthe response of an action classifier for a real-world agent. The Artificial\\\\nNeural Networks (ANN) based classifier relies on dimension reduction\\\\nto the system’s inputs in order to require a smaller dataset for training.\\\\nTo achieve it, initially, an external depth sensor provides the skeleton\\\\njoints features, and then eigenvalues decomposition reduces the input’s\\\\ndimension. The major insight of the work was the requirement of\\\\na tiny dataset, being flexible for several applications. In this work,')] \\n\\n LLM generation: Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\")]]}}, 'run_id': '0e2600e5-1afc-46c2-aa48-87e926234b06', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', 'b5c93b09-a50a-44cd-b6f9-727ec439b437', 'b8b803a0-fd70-43b7-bb8d-9a086c0880be']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_parser_start', 'data': {'input': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_kx9v', 'function': {'arguments': '{\"binary_score\":\"yes\"}', 'name': 'GradeHallucinations'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0e2600e5-1afc-46c2-aa48-87e926234b06', tool_calls=[{'name': 'GradeHallucinations', 'args': {'binary_score': 'yes'}, 'id': 'call_kx9v'}], usage_metadata={'input_tokens': 2146, 'output_tokens': 69, 'total_tokens': 2215})}, 'name': 'PydanticToolsParser', 'tags': ['seq:step:3'], 'run_id': '0c82a410-f5ee-4056-a27b-e929515505cf', 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', 'b5c93b09-a50a-44cd-b6f9-727ec439b437', 'b8b803a0-fd70-43b7-bb8d-9a086c0880be']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_parser_end', 'data': {'output': GradeHallucinations(binary_score='yes'), 'input': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_kx9v', 'function': {'arguments': '{\"binary_score\":\"yes\"}', 'name': 'GradeHallucinations'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0e2600e5-1afc-46c2-aa48-87e926234b06', tool_calls=[{'name': 'GradeHallucinations', 'args': {'binary_score': 'yes'}, 'id': 'call_kx9v'}], usage_metadata={'input_tokens': 2146, 'output_tokens': 69, 'total_tokens': 2215})}, 'run_id': '0c82a410-f5ee-4056-a27b-e929515505cf', 'name': 'PydanticToolsParser', 'tags': ['seq:step:3'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', 'b5c93b09-a50a-44cd-b6f9-727ec439b437', 'b8b803a0-fd70-43b7-bb8d-9a086c0880be']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_end', 'data': {'output': GradeHallucinations(binary_score='yes'), 'input': {'documents': [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\ndedicated to understand, design, and evaluate robotic systems\\nfor use by or with humans” [1]. The interaction can occur in\\ntwo different ways: remote and proximate. They are largely\\ninfluenced by the proximity of the human and the robot.\\nWorks like [2–5] bring good examples of how remote com-\\nmunication can be exploited in several applications, such as\\n\\n\\n\\x02    Kevin Braathen de Carvalho\\n     kevin.carvalho@ufv.br\\n     Daniel Khede Dourado Villa\\n     danielkdv@gmail.com\\n\\n     M´ario Sarcinelli-Filho\\n     mario.sarcinelli@ufes.br\\n     Alexandre Santos Brand˜ao\\n     alexandre.brandao@ufv.br\\n\\n1    Graduate Program on Computer Science, Federal University\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\n2    Graduate Program on Electrical Engineering, Federal\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\nranging from face, gesture, movement and speech pattern\\nrecognition, yet much to be developed. There are various\\napplications for robotics such as control – for general mobile\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\nsecurity and surveillance robots [11], home automation [12],\\nin-car recognition and many others, all of which require\\nsome level of interaction with humans, preferably as a two-\\nway conversation [13], [14]. Although efficient, most of the\\nprevious works bases themselves on recognition of phonemes\\nor a small, fixed set of keywords, usually in controlled\\nenvironments, which limits their flexibility and replicability.\\nOur goal is developing a natural, intuitive interface, working\\nas a small conversation between an autonomous robot and\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\nlow-cost solution, unlocking new possibilities for further study\\nand development of better, more autonomous and environment-\\nadaptable robots.\\n                       I. INTRODUCTION\\n   Developing robots capable of autonomously deciding the\\nbest course of action depending on events, environment and\\nuser specifications, are one of the major goals in robotics\\nand correctly perceiving these user’s specifications is critical\\nfor making decisions and acting in the most reasonable way.\\nTherefore a Human-Robot Interface (HRI) capable of both\\nsatisfying the user and performing real time task decision\\nmaking according to environmental changes is a current\\nchallenge.\\n   There are multiple models for HRI, and existing literature\\nsuggests speech recognition is user-friendly, intuitive and\\neffective for various applications [1], [2], [3], [4]. Many\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\nAssistive Robotics.\\n    This paper main contribution is a human–robot interaction frame-\\nwork, having as motivation the development of a Social Assistive\\nRobotics application. The system has easy-to-follow implementation\\nand provides a clear path to be used as a more hands-on approach.\\nIts topics facilitate the teaching tasks, for instance, the description and\\nthe response of an action classifier for a real-world agent. The Artificial\\nNeural Networks (ANN) based classifier relies on dimension reduction\\nto the system’s inputs in order to require a smaller dataset for training.\\nTo achieve it, initially, an external depth sensor provides the skeleton\\njoints features, and then eigenvalues decomposition reduces the input’s\\ndimension. The major insight of the work was the requirement of\\na tiny dataset, being flexible for several applications. In this work,')], 'generation': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.'}}, 'run_id': 'b8b803a0-fd70-43b7-bb8d-9a086c0880be', 'name': 'RunnableSequence', 'tags': [], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', 'b5c93b09-a50a-44cd-b6f9-727ec439b437']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_start', 'data': {'input': {'question': 'what is human robotic', 'generation': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.'}}, 'name': 'RunnableSequence', 'tags': [], 'run_id': 'c5f80e84-36d9-48e3-863e-7e814300e12c', 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', 'b5c93b09-a50a-44cd-b6f9-727ec439b437']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_prompt_start', 'data': {'input': {'question': 'what is human robotic', 'generation': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.'}}, 'name': 'PromptTemplate', 'tags': ['seq:step:1'], 'run_id': '32e918fb-e54b-4747-9e37-000200248c5b', 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', 'b5c93b09-a50a-44cd-b6f9-727ec439b437', 'c5f80e84-36d9-48e3-863e-7e814300e12c']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_prompt_end', 'data': {'output': StringPromptValue(text=\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an answer addresses / resolves a question.\\nGive a binary score 'yes' or 'no', where 'yes' means that the answer resolves the question. \\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\nUser question: \\n\\n what is human robotic \\n\\n LLM generation: Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"), 'input': {'question': 'what is human robotic', 'generation': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.'}}, 'run_id': '32e918fb-e54b-4747-9e37-000200248c5b', 'name': 'PromptTemplate', 'tags': ['seq:step:1'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', 'b5c93b09-a50a-44cd-b6f9-727ec439b437', 'c5f80e84-36d9-48e3-863e-7e814300e12c']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_start', 'data': {'input': {'messages': [[HumanMessage(content=\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an answer addresses / resolves a question.\\nGive a binary score 'yes' or 'no', where 'yes' means that the answer resolves the question. \\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\nUser question: \\n\\n what is human robotic \\n\\n LLM generation: Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\")]]}}, 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'run_id': 'fb854cc4-a3fa-45b9-b4f0-44aec917fc6f', 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', 'b5c93b09-a50a-44cd-b6f9-727ec439b437', 'c5f80e84-36d9-48e3-863e-7e814300e12c']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_yx8t', 'function': {'arguments': '{\"binary_score\":\"yes\"}', 'name': 'GradeAnswer'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-fb854cc4-a3fa-45b9-b4f0-44aec917fc6f', tool_calls=[{'name': 'GradeAnswer', 'args': {'binary_score': 'yes'}, 'id': 'call_yx8t'}], usage_metadata={'input_tokens': 916, 'output_tokens': 67, 'total_tokens': 983}, tool_call_chunks=[{'name': 'GradeAnswer', 'args': '{\"binary_score\":\"yes\"}', 'id': 'call_yx8t', 'index': None}])}, 'run_id': 'fb854cc4-a3fa-45b9-b4f0-44aec917fc6f', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', 'b5c93b09-a50a-44cd-b6f9-727ec439b437', 'c5f80e84-36d9-48e3-863e-7e814300e12c']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chat_model_end', 'data': {'output': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_yx8t', 'function': {'arguments': '{\"binary_score\":\"yes\"}', 'name': 'GradeAnswer'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-fb854cc4-a3fa-45b9-b4f0-44aec917fc6f', tool_calls=[{'name': 'GradeAnswer', 'args': {'binary_score': 'yes'}, 'id': 'call_yx8t'}], usage_metadata={'input_tokens': 916, 'output_tokens': 67, 'total_tokens': 983}), 'input': {'messages': [[HumanMessage(content=\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an answer addresses / resolves a question.\\nGive a binary score 'yes' or 'no', where 'yes' means that the answer resolves the question. \\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\nUser question: \\n\\n what is human robotic \\n\\n LLM generation: Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\")]]}}, 'run_id': 'fb854cc4-a3fa-45b9-b4f0-44aec917fc6f', 'name': 'ChatGroq', 'tags': ['seq:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0, 'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', 'b5c93b09-a50a-44cd-b6f9-727ec439b437', 'c5f80e84-36d9-48e3-863e-7e814300e12c']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_parser_start', 'data': {'input': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_yx8t', 'function': {'arguments': '{\"binary_score\":\"yes\"}', 'name': 'GradeAnswer'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-fb854cc4-a3fa-45b9-b4f0-44aec917fc6f', tool_calls=[{'name': 'GradeAnswer', 'args': {'binary_score': 'yes'}, 'id': 'call_yx8t'}], usage_metadata={'input_tokens': 916, 'output_tokens': 67, 'total_tokens': 983})}, 'name': 'PydanticToolsParser', 'tags': ['seq:step:3'], 'run_id': '37dddd7d-2962-404c-b0b9-dc9b50137833', 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', 'b5c93b09-a50a-44cd-b6f9-727ec439b437', 'c5f80e84-36d9-48e3-863e-7e814300e12c']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_parser_end', 'data': {'output': GradeAnswer(binary_score='yes'), 'input': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_yx8t', 'function': {'arguments': '{\"binary_score\":\"yes\"}', 'name': 'GradeAnswer'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-fb854cc4-a3fa-45b9-b4f0-44aec917fc6f', tool_calls=[{'name': 'GradeAnswer', 'args': {'binary_score': 'yes'}, 'id': 'call_yx8t'}], usage_metadata={'input_tokens': 916, 'output_tokens': 67, 'total_tokens': 983})}, 'run_id': '37dddd7d-2962-404c-b0b9-dc9b50137833', 'name': 'PydanticToolsParser', 'tags': ['seq:step:3'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', 'b5c93b09-a50a-44cd-b6f9-727ec439b437', 'c5f80e84-36d9-48e3-863e-7e814300e12c']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_end', 'data': {'output': GradeAnswer(binary_score='yes'), 'input': {'question': 'what is human robotic', 'generation': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.'}}, 'run_id': 'c5f80e84-36d9-48e3-863e-7e814300e12c', 'name': 'RunnableSequence', 'tags': [], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b', 'b5c93b09-a50a-44cd-b6f9-727ec439b437']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_end', 'data': {'output': 'finalize_response', 'input': {'retries': 0, 'candidate_answer': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.', 'messages': [HumanMessage(content='what is human robotic', id='dade212c-8c0f-4577-8b97-d9073549e852')], 'question': 'what is human robotic', 'documents': [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\ndedicated to understand, design, and evaluate robotic systems\\nfor use by or with humans” [1]. The interaction can occur in\\ntwo different ways: remote and proximate. They are largely\\ninfluenced by the proximity of the human and the robot.\\nWorks like [2–5] bring good examples of how remote com-\\nmunication can be exploited in several applications, such as\\n\\n\\n\\x02    Kevin Braathen de Carvalho\\n     kevin.carvalho@ufv.br\\n     Daniel Khede Dourado Villa\\n     danielkdv@gmail.com\\n\\n     M´ario Sarcinelli-Filho\\n     mario.sarcinelli@ufes.br\\n     Alexandre Santos Brand˜ao\\n     alexandre.brandao@ufv.br\\n\\n1    Graduate Program on Computer Science, Federal University\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\n2    Graduate Program on Electrical Engineering, Federal\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\nranging from face, gesture, movement and speech pattern\\nrecognition, yet much to be developed. There are various\\napplications for robotics such as control – for general mobile\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\nsecurity and surveillance robots [11], home automation [12],\\nin-car recognition and many others, all of which require\\nsome level of interaction with humans, preferably as a two-\\nway conversation [13], [14]. Although efficient, most of the\\nprevious works bases themselves on recognition of phonemes\\nor a small, fixed set of keywords, usually in controlled\\nenvironments, which limits their flexibility and replicability.\\nOur goal is developing a natural, intuitive interface, working\\nas a small conversation between an autonomous robot and\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\nlow-cost solution, unlocking new possibilities for further study\\nand development of better, more autonomous and environment-\\nadaptable robots.\\n                       I. INTRODUCTION\\n   Developing robots capable of autonomously deciding the\\nbest course of action depending on events, environment and\\nuser specifications, are one of the major goals in robotics\\nand correctly perceiving these user’s specifications is critical\\nfor making decisions and acting in the most reasonable way.\\nTherefore a Human-Robot Interface (HRI) capable of both\\nsatisfying the user and performing real time task decision\\nmaking according to environmental changes is a current\\nchallenge.\\n   There are multiple models for HRI, and existing literature\\nsuggests speech recognition is user-friendly, intuitive and\\neffective for various applications [1], [2], [3], [4]. Many\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\nAssistive Robotics.\\n    This paper main contribution is a human–robot interaction frame-\\nwork, having as motivation the development of a Social Assistive\\nRobotics application. The system has easy-to-follow implementation\\nand provides a clear path to be used as a more hands-on approach.\\nIts topics facilitate the teaching tasks, for instance, the description and\\nthe response of an action classifier for a real-world agent. The Artificial\\nNeural Networks (ANN) based classifier relies on dimension reduction\\nto the system’s inputs in order to require a smaller dataset for training.\\nTo achieve it, initially, an external depth sensor provides the skeleton\\njoints features, and then eigenvalues decomposition reduces the input’s\\ndimension. The major insight of the work was the requirement of\\na tiny dataset, being flexible for several applications. In this work,')], 'web_fallback': True}}, 'run_id': 'b5c93b09-a50a-44cd-b6f9-727ec439b437', 'name': 'grade_generation_v_documents_and_question', 'tags': ['seq:step:3'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_start', 'data': {'input': {'retries': 0, 'candidate_answer': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.'}}, 'name': 'ChannelWrite<branch:generate:grade_generation_v_documents_and_question:finalize_response>', 'tags': ['seq:step:3', 'langsmith:hidden'], 'run_id': 'd53bfdce-2bcd-4ee6-b547-ac0692f3ce8c', 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_end', 'data': {'output': {'retries': 0, 'candidate_answer': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.'}, 'input': {'retries': 0, 'candidate_answer': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.'}}, 'run_id': 'd53bfdce-2bcd-4ee6-b547-ac0692f3ce8c', 'name': 'ChannelWrite<branch:generate:grade_generation_v_documents_and_question:finalize_response>', 'tags': ['seq:step:3', 'langsmith:hidden'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '04d591cf-bee1-4014-89ed-873d7840078b']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_stream', 'run_id': '04d591cf-bee1-4014-89ed-873d7840078b', 'name': 'generate', 'tags': ['graph:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'data': {'chunk': {'retries': 0, 'candidate_answer': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.'}}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_end', 'data': {'output': {'retries': 0, 'candidate_answer': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.'}, 'input': {'messages': [HumanMessage(content='what is human robotic', id='dade212c-8c0f-4577-8b97-d9073549e852')], 'question': 'what is human robotic', 'documents': [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\ndedicated to understand, design, and evaluate robotic systems\\nfor use by or with humans” [1]. The interaction can occur in\\ntwo different ways: remote and proximate. They are largely\\ninfluenced by the proximity of the human and the robot.\\nWorks like [2–5] bring good examples of how remote com-\\nmunication can be exploited in several applications, such as\\n\\n\\n\\x02    Kevin Braathen de Carvalho\\n     kevin.carvalho@ufv.br\\n     Daniel Khede Dourado Villa\\n     danielkdv@gmail.com\\n\\n     M´ario Sarcinelli-Filho\\n     mario.sarcinelli@ufes.br\\n     Alexandre Santos Brand˜ao\\n     alexandre.brandao@ufv.br\\n\\n1    Graduate Program on Computer Science, Federal University\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\n2    Graduate Program on Electrical Engineering, Federal\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\nranging from face, gesture, movement and speech pattern\\nrecognition, yet much to be developed. There are various\\napplications for robotics such as control – for general mobile\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\nsecurity and surveillance robots [11], home automation [12],\\nin-car recognition and many others, all of which require\\nsome level of interaction with humans, preferably as a two-\\nway conversation [13], [14]. Although efficient, most of the\\nprevious works bases themselves on recognition of phonemes\\nor a small, fixed set of keywords, usually in controlled\\nenvironments, which limits their flexibility and replicability.\\nOur goal is developing a natural, intuitive interface, working\\nas a small conversation between an autonomous robot and\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\nlow-cost solution, unlocking new possibilities for further study\\nand development of better, more autonomous and environment-\\nadaptable robots.\\n                       I. INTRODUCTION\\n   Developing robots capable of autonomously deciding the\\nbest course of action depending on events, environment and\\nuser specifications, are one of the major goals in robotics\\nand correctly perceiving these user’s specifications is critical\\nfor making decisions and acting in the most reasonable way.\\nTherefore a Human-Robot Interface (HRI) capable of both\\nsatisfying the user and performing real time task decision\\nmaking according to environmental changes is a current\\nchallenge.\\n   There are multiple models for HRI, and existing literature\\nsuggests speech recognition is user-friendly, intuitive and\\neffective for various applications [1], [2], [3], [4]. Many\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\nAssistive Robotics.\\n    This paper main contribution is a human–robot interaction frame-\\nwork, having as motivation the development of a Social Assistive\\nRobotics application. The system has easy-to-follow implementation\\nand provides a clear path to be used as a more hands-on approach.\\nIts topics facilitate the teaching tasks, for instance, the description and\\nthe response of an action classifier for a real-world agent. The Artificial\\nNeural Networks (ANN) based classifier relies on dimension reduction\\nto the system’s inputs in order to require a smaller dataset for training.\\nTo achieve it, initially, an external depth sensor provides the skeleton\\njoints features, and then eigenvalues decomposition reduces the input’s\\ndimension. The major insight of the work was the requirement of\\na tiny dataset, being flexible for several applications. In this work,')], 'candidate_answer': None, 'retries': None, 'web_fallback': True}}, 'run_id': '04d591cf-bee1-4014-89ed-873d7840078b', 'name': 'generate', 'tags': ['graph:step:2'], 'metadata': {'langgraph_step': 2, 'langgraph_node': 'generate', 'langgraph_triggers': ['document_search'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_stream', 'run_id': 'e0530f4e-58ac-40f3-8d10-ceb0c50030f2', 'name': 'LangGraph', 'tags': [], 'metadata': {}, 'data': {'chunk': {'generate': {'candidate_answer': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.', 'retries': 0}}}, 'parent_ids': []}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_start', 'data': {}, 'name': 'finalize_response', 'tags': ['graph:step:3'], 'run_id': '640eee0f-6b4f-43e3-9a73-c0b70a1a5dfa', 'metadata': {'langgraph_step': 3, 'langgraph_node': 'finalize_response', 'langgraph_triggers': ['branch:generate:grade_generation_v_documents_and_question:finalize_response'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_start', 'data': {'input': {'messages': [AIMessage(content='Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.')]}}, 'name': 'ChannelWrite<finalize_response,messages,question,documents,candidate_answer,retries,web_fallback>', 'tags': ['seq:step:2', 'langsmith:hidden'], 'run_id': '5b18c195-1ff4-4175-9152-9cde19e77226', 'metadata': {'langgraph_step': 3, 'langgraph_node': 'finalize_response', 'langgraph_triggers': ['branch:generate:grade_generation_v_documents_and_question:finalize_response'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '640eee0f-6b4f-43e3-9a73-c0b70a1a5dfa']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_end', 'data': {'output': {'messages': [AIMessage(content='Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.')]}, 'input': {'messages': [AIMessage(content='Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.')]}}, 'run_id': '5b18c195-1ff4-4175-9152-9cde19e77226', 'name': 'ChannelWrite<finalize_response,messages,question,documents,candidate_answer,retries,web_fallback>', 'tags': ['seq:step:2', 'langsmith:hidden'], 'metadata': {'langgraph_step': 3, 'langgraph_node': 'finalize_response', 'langgraph_triggers': ['branch:generate:grade_generation_v_documents_and_question:finalize_response'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2', '640eee0f-6b4f-43e3-9a73-c0b70a1a5dfa']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_stream', 'run_id': '640eee0f-6b4f-43e3-9a73-c0b70a1a5dfa', 'name': 'finalize_response', 'tags': ['graph:step:3'], 'metadata': {'langgraph_step': 3, 'langgraph_node': 'finalize_response', 'langgraph_triggers': ['branch:generate:grade_generation_v_documents_and_question:finalize_response'], 'langgraph_task_idx': 0}, 'data': {'chunk': {'messages': [AIMessage(content='Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.')]}}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_end', 'data': {'output': {'messages': [AIMessage(content='Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.')]}, 'input': {'messages': [HumanMessage(content='what is human robotic', id='dade212c-8c0f-4577-8b97-d9073549e852')], 'question': 'what is human robotic', 'documents': [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\ndedicated to understand, design, and evaluate robotic systems\\nfor use by or with humans” [1]. The interaction can occur in\\ntwo different ways: remote and proximate. They are largely\\ninfluenced by the proximity of the human and the robot.\\nWorks like [2–5] bring good examples of how remote com-\\nmunication can be exploited in several applications, such as\\n\\n\\n\\x02    Kevin Braathen de Carvalho\\n     kevin.carvalho@ufv.br\\n     Daniel Khede Dourado Villa\\n     danielkdv@gmail.com\\n\\n     M´ario Sarcinelli-Filho\\n     mario.sarcinelli@ufes.br\\n     Alexandre Santos Brand˜ao\\n     alexandre.brandao@ufv.br\\n\\n1    Graduate Program on Computer Science, Federal University\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\n2    Graduate Program on Electrical Engineering, Federal\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\nranging from face, gesture, movement and speech pattern\\nrecognition, yet much to be developed. There are various\\napplications for robotics such as control – for general mobile\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\nsecurity and surveillance robots [11], home automation [12],\\nin-car recognition and many others, all of which require\\nsome level of interaction with humans, preferably as a two-\\nway conversation [13], [14]. Although efficient, most of the\\nprevious works bases themselves on recognition of phonemes\\nor a small, fixed set of keywords, usually in controlled\\nenvironments, which limits their flexibility and replicability.\\nOur goal is developing a natural, intuitive interface, working\\nas a small conversation between an autonomous robot and\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\nlow-cost solution, unlocking new possibilities for further study\\nand development of better, more autonomous and environment-\\nadaptable robots.\\n                       I. INTRODUCTION\\n   Developing robots capable of autonomously deciding the\\nbest course of action depending on events, environment and\\nuser specifications, are one of the major goals in robotics\\nand correctly perceiving these user’s specifications is critical\\nfor making decisions and acting in the most reasonable way.\\nTherefore a Human-Robot Interface (HRI) capable of both\\nsatisfying the user and performing real time task decision\\nmaking according to environmental changes is a current\\nchallenge.\\n   There are multiple models for HRI, and existing literature\\nsuggests speech recognition is user-friendly, intuitive and\\neffective for various applications [1], [2], [3], [4]. Many\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\nAssistive Robotics.\\n    This paper main contribution is a human–robot interaction frame-\\nwork, having as motivation the development of a Social Assistive\\nRobotics application. The system has easy-to-follow implementation\\nand provides a clear path to be used as a more hands-on approach.\\nIts topics facilitate the teaching tasks, for instance, the description and\\nthe response of an action classifier for a real-world agent. The Artificial\\nNeural Networks (ANN) based classifier relies on dimension reduction\\nto the system’s inputs in order to require a smaller dataset for training.\\nTo achieve it, initially, an external depth sensor provides the skeleton\\njoints features, and then eigenvalues decomposition reduces the input’s\\ndimension. The major insight of the work was the requirement of\\na tiny dataset, being flexible for several applications. In this work,')], 'candidate_answer': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.', 'retries': 0, 'web_fallback': True}}, 'run_id': '640eee0f-6b4f-43e3-9a73-c0b70a1a5dfa', 'name': 'finalize_response', 'tags': ['graph:step:3'], 'metadata': {'langgraph_step': 3, 'langgraph_node': 'finalize_response', 'langgraph_triggers': ['branch:generate:grade_generation_v_documents_and_question:finalize_response'], 'langgraph_task_idx': 0}, 'parent_ids': ['e0530f4e-58ac-40f3-8d10-ceb0c50030f2']}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_stream', 'run_id': 'e0530f4e-58ac-40f3-8d10-ceb0c50030f2', 'name': 'LangGraph', 'tags': [], 'metadata': {}, 'data': {'chunk': {'finalize_response': {'messages': [AIMessage(content='Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.', id='1ea84163-b950-416c-99f2-88ee90a1df4e')]}}}, 'parent_ids': []}\n",
      "-*--*--*--*--*--*--*--*--*--*-\n",
      "{'event': 'on_chain_end', 'data': {'output': {'messages': [HumanMessage(content='what is human robotic', id='dade212c-8c0f-4577-8b97-d9073549e852'), AIMessage(content='Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.', id='1ea84163-b950-416c-99f2-88ee90a1df4e')], 'question': 'what is human robotic', 'documents': [Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Gestures-teleoperation of a heterogeneous multi-robot system', 'sources': 'https://drive.google.com/file/d/1tIgmmatYw0BpRGNIokM5RutfxHzX-cRq'}, page_content='Human-robot interaction can be defined as “a field of study\\ndedicated to understand, design, and evaluate robotic systems\\nfor use by or with humans” [1]. The interaction can occur in\\ntwo different ways: remote and proximate. They are largely\\ninfluenced by the proximity of the human and the robot.\\nWorks like [2–5] bring good examples of how remote com-\\nmunication can be exploited in several applications, such as\\n\\n\\n\\x02    Kevin Braathen de Carvalho\\n     kevin.carvalho@ufv.br\\n     Daniel Khede Dourado Villa\\n     danielkdv@gmail.com\\n\\n     M´ario Sarcinelli-Filho\\n     mario.sarcinelli@ufes.br\\n     Alexandre Santos Brand˜ao\\n     alexandre.brandao@ufv.br\\n\\n1    Graduate Program on Computer Science, Federal University\\n     of Vic¸osa, 36570-900, Vic¸osa, Minas Gerais, Brazil\\n2    Graduate Program on Electrical Engineering, Federal\\n     University of Esp´ırito Santo, 29075-910, Vit´oria,\\n     Esp´ırito Santo, Brazil'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='There are many proposed HRI for different types of robots,\\nranging from face, gesture, movement and speech pattern\\nrecognition, yet much to be developed. There are various\\napplications for robotics such as control – for general mobile\\nrobots [5], [6], [7], prosthetics and robot arms [8], [9],\\nrobotic wheelchairs [10] – as well as human-robot dialogue,\\nsecurity and surveillance robots [11], home automation [12],\\nin-car recognition and many others, all of which require\\nsome level of interaction with humans, preferably as a two-\\nway conversation [13], [14]. Although efficient, most of the\\nprevious works bases themselves on recognition of phonemes\\nor a small, fixed set of keywords, usually in controlled\\nenvironments, which limits their flexibility and replicability.\\nOur goal is developing a natural, intuitive interface, working\\nas a small conversation between an autonomous robot and\\nits user, despite environment noise, user language or accent,'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Modeling and development of a spoken natural language interface for  autonomous robot interaction', 'sources': 'https://drive.google.com/file/d/1bMYjKuhSJme7WRASsZBHqgh8iURQTjBi'}, page_content='technologies and devices applied guarantee a light, efficient and\\nlow-cost solution, unlocking new possibilities for further study\\nand development of better, more autonomous and environment-\\nadaptable robots.\\n                       I. INTRODUCTION\\n   Developing robots capable of autonomously deciding the\\nbest course of action depending on events, environment and\\nuser specifications, are one of the major goals in robotics\\nand correctly perceiving these user’s specifications is critical\\nfor making decisions and acting in the most reasonable way.\\nTherefore a Human-Robot Interface (HRI) capable of both\\nsatisfying the user and performing real time task decision\\nmaking according to environmental changes is a current\\nchallenge.\\n   There are multiple models for HRI, and existing literature\\nsuggests speech recognition is user-friendly, intuitive and\\neffective for various applications [1], [2], [3], [4]. Many\\napproaches brought forth applicable, efficient algorithms for'), Document(metadata={'article_area': 'HR - Interação Humano-Robô', 'article_language': 'en', 'article_title': 'Action recognition for educational proposals applying concepts of Social Assistive Robotics', 'sources': 'https://drive.google.com/file/d/1lsBkPp9osOCCtwO_ftdW0vIXWWGiRaut'}, page_content='preserves its attributes and the proposal to be an application of Socially\\nAssistive Robotics.\\n    This paper main contribution is a human–robot interaction frame-\\nwork, having as motivation the development of a Social Assistive\\nRobotics application. The system has easy-to-follow implementation\\nand provides a clear path to be used as a more hands-on approach.\\nIts topics facilitate the teaching tasks, for instance, the description and\\nthe response of an action classifier for a real-world agent. The Artificial\\nNeural Networks (ANN) based classifier relies on dimension reduction\\nto the system’s inputs in order to require a smaller dataset for training.\\nTo achieve it, initially, an external depth sensor provides the skeleton\\njoints features, and then eigenvalues decomposition reduces the input’s\\ndimension. The major insight of the work was the requirement of\\na tiny dataset, being flexible for several applications. In this work,')], 'candidate_answer': 'Human-robot interaction (HRI) is a field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans.', 'retries': 0, 'web_fallback': True}}, 'run_id': 'e0530f4e-58ac-40f3-8d10-ceb0c50030f2', 'name': 'LangGraph', 'tags': [], 'metadata': {}, 'parent_ids': []}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "inputs = {\"messages\": [(\"human\", 'what is human robotic')]}\n",
    "async for event in graph.astream_events(inputs, version=\"v2\"):\n",
    "    print(\"-*-\" * 10)\n",
    "    print(event)\n",
    "    if (\n",
    "        event[\"event\"] == \"on_chat_model_stream\"\n",
    "    ):\n",
    "        print(event[\"data\"][\"chunk\"].content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
